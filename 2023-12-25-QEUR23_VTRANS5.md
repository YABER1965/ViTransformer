---
title: QEUR23_VTRANS5: [Keras]アテンションマップを作ってみる
date: 2023-12-25
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VTRANS5: [Keras]アテンションマップを作ってみる

## ～ とりあえず、「やりたいことのひな形」ができた ～

QEU:FOUNDER ： “今回は、前回作った（分類）予測モデルを作って、**「アテンション・マップ」**をつくってみましょう。”

C部長 : “なにそれ？アテンション・マップって、予測と関係があるんです？”

QEU:FOUNDER ： “モデルを読み込んで、入力画像を読み込んで濃淡を出力する方法です。”

![imageJRL8-6-1](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-1.jpg)

D先生 ： “ちょっと気になったので、アテンション・マップについて調べてみました。”

![imageJRL8-6-2](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-2.jpg)

The attention maps of Vision Transformer (ViT) are matrices that represent the im-portance of different parts of an input image to different parts of the model’s learned representations. In ViT, the entire image of the input data is first divided in-to non-overlapping patches, which are then flattened and fed into the transformer encoder (more about the architecture below). 
Vision Transformer (ViT) のアテンション マップは、モデルの学習された表現のさまざまな部分に対する入力画像のさまざまな部分の重要性を表す行列です。 ViT では、入力データのイメージ全体がまず重複しないパッチに分割され、次にそれらが平坦化されてトランス エンコーダーに供給されます (アーキテクチャについては以下で詳しく説明します)。

Attention maps refer to the visualizations of the attention weights that are calculat-ed between each token (or patch) in the image and all other tokens. These attention maps are calculated using a self-attention mechanism, where each token attends to all other tokens to obtain a weighted sum of their representations. 
The attention maps can be visualized as a grid of heatmaps, where each heatmap represents the attention weights between a given token and all other tokens. The brighter the color of a pixel in the heatmap, the higher the attention weight between the corresponding tokens. By analyzing the attention maps, we can gain insights in-to which parts of the image are most important for the classification task at hand.   
アテンション マップは、画像内の各トークン (またはパッチ) と他のすべてのトークンの間で計算されるアテンション ウェイトの視覚化を指します。 これらのアテンション マップはセルフ アテンション メカニズムを使用して計算されます。このメカニズムでは、各トークンが他のすべてのトークンに注目して、それらの表現の重み付き合計を取得します。
アテンション マップはヒートマップのグリッドとして視覚化できます。各ヒートマップは、特定のトークンと他のすべてのトークンの間のアテンションの重みを表します。 ヒートマップ内のピクセルの色が明るいほど、対応するトークン間のアテンションの重みが高くなります。 アテンション マップを分析することで、画像のどの部分が当面の分類タスクにとって最も重要であるかについて洞察を得ることができます。

C部長 : “よくわかりませんが、ViTモデルの一部（セルフアテンション）から計算できるんですね。”

D先生 ： “もともと、ViTモデルはアテンションでできているので、画像にアテンションの量を分布させただけのようですね。”

QEU:FOUNDER ： “わざわざ調べてくれてありがとうございます。何はともあれ、アテンション・マップを生成するためのプログラムを紹介して、その後で計算結果（アテンション・マップ）を鑑賞してみましょう。”

```python
#####
# TRAINING VIT PROGRAM(FLOWER)
#####
import numpy as np
import pandas as pd
from PIL import Image 

# ------
# CLASS NAMES
class_names = ['daisy','dandelion','roses','sunflowers','tulips']

# ------
def create_labels(class_names, all_files):

    # ------
    num_df = len(all_files)

    # ---
    arr_class = []
    arr_index = []
    for row in range(num_df):    # num_df
        name_file = all_files[row]
        for i, str_class in enumerate(class_names):
            if str_class in name_file:
                #print(i, str_class)
                arr_class.append(str_class)
                arr_index.append(i)
    # ---
    np_index = np.array([arr_index]) 

    return num_df, arr_class, np_index

# -----
# TEST
# -----
DF_TEST = pd.read_csv('testing_filesG.csv', dtype='str')
#print(DF_TEST)
# ---
temp_base_paths = DF_TEST.loc[:,"base_path"].values
temp_type_dirs = DF_TEST.loc[:,"type_dir"].values
temp_file_names = DF_TEST.loc[:,"file_name"].values
# ---
test_base_paths = []
test_type_dirs = []
test_file_names = []
# ---
for i in range(len(DF_TEST)):
    base_path = temp_base_paths[i]
    type_dir = temp_type_dirs[i]
    file_name = temp_file_names[i]  
    if 'webp' not in file_name:
        test_base_paths.append(base_path)
        test_type_dirs.append(type_dir)
        test_file_names.append(file_name)

# -----
# test
num_test, test_class, test_index = create_labels(class_names, test_type_dirs)
print(test_class[0:20])
print(test_index[0,0:20])
print(test_index.shape)

###
# CREATE X-Y INPUT DATASET
###
# 画像の読み込み -> ベクトル化
IMAGE_SIZE = 224

# ---
# 画像ベクトルを生成する
def create_vector(base_path, type_dir, file_name, IMAGE_SIZE):

    img = (Image.open(base_path + '/' + type_dir + '/' + file_name)) 
    # Resize
    #img_resize = img.resize((IMAGE_SIZE, IMAGE_SIZE))
    # display the image 
    #display(img_resize)
    #img_arr = np.asarray(img_resize)
    img_arr = np.asarray(img)
    val_shape = img_arr.shape
    #print(img_arr.shape) 
    
    return img_arr, val_shape

# ------
# TEST
mx_test = np.array([])
for i in range(num_test):
    base_path = test_base_paths[i]
    type_dir = test_type_dirs[i]
    file_name = test_file_names[i]
    img_arr, val_shape = create_vector(base_path, type_dir, file_name, IMAGE_SIZE)
    if i == 0:
        mx_test = np.array([img_arr])
    else:
        mx_test = np.concatenate([mx_test, np.array([img_arr])],0)
    if i%50 == 0:
        print(i)
# ---
print(mx_test.shape)

# -----------
# IMPORT PACKAGES
import os
os.environ['PYTHONHASHSEED'] = '0'
import tensorflow as tf
os.environ['TF_DETERMINISTIC_OPS'] = 'true'
os.environ['TF_CUDNN_DETERMINISTIC'] = 'true'
import random as rn

SEED = 123
def reset_random_seeds():
    tf.random.set_seed(SEED)
    np.random.seed(SEED)
    rn.seed(SEED)
reset_random_seeds()    

# -----------
# ライブラリインポート
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, BatchNormalization,Flatten

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras import optimizers
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
import tensorflow_addons as tfa

from vit_keras import vit, utils, visualize
#from sklearn.model_selection import train_test_split

# ---
X_test = mx_test
y_test = test_index[0]

# 変数定義
image_size = 224 #CIFAR10の元々のサイズは32。これを128にリサイズする。
input_shape=(image_size,image_size,3)

# 予測するクラス数（CIFAR10の場合は10）
num_classes = 5

# -----
# モデル定義(Fine_tuning)
def buildModel_ViT():
    vit_model = vit.vit_b16(
        image_size = image_size,
        activation = 'sigmoid',
        pretrained = True,
        include_top = False,
        pretrained_top = False)
    model = tf.keras.Sequential([
        vit_model,
        tf.keras.layers.Flatten(),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dense(21, activation = tfa.activations.gelu),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dense(num_classes, 'softmax')
    ],
    name = 'vision_transformer')
    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss="categorical_crossentropy", met-rics=["accuracy"])
    
    return model

# Saving Model
!pip install pyyaml h5py  # Required to save models in HDF5 format
print(tf.version.VERSION)

# モデルのロード
from tensorflow.python.keras.models import load_model

# ----
# (参考)復元する
# Create a new model instance
model = buildModel_ViT()
model.summary() #モデル情報を出力

```

**（モデルの構造）**

![imageJRL8-6-3](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-3.jpg)

QEU:FOUNDER ： “ここまでですが、前回のテスト・データセットだけを読み込んで、その後で前回作成したモデルを読み込みました。”

D先生 ： “今回、初めてモデルの構造を見ました。かなり大きなパラメータを持っているんですね。”

```python
# Load the previously saved weights
model.load_weights('./files/test_model.h5')

# -----
# モデルから予測する
X = X_test
pred = model.predict(X)
print(pred[0:10])

# 予測結果の確認
df_pred = pd.DataFrame(pred)
idx_pred = np.array(df_pred.idxmax(axis=1))
print(idx_pred[0:10])

# -----
df_pred = pd.DataFrame(idx_pred)
df_y = pd.DataFrame(y_test)
df_result = pd.concat([df_y, df_pred], axis=1)
df_result.columns = ['y','pred']
display(df_result)

# -----
# MATPLOTLIBを使う
from matplotlib import pyplot as plt

# ------
# 結果を比較する
plt.figure(figsize=(12,12))
icount , vcount = 0, 0
for image,label,tname in zip( X_test[0:1280], idx_pred[0:1280], y_test[0:1280]):
    if icount%80 == 0:
        ax=plt.subplot(4,4,vcount+1)
        plt.imshow(image)
        plt.title("True Label :"+ class_names[tname] + "\n" + "Predicted Label  : " + class_names[label])
        plt.axis("off")
        vcount = vcount + 1
    icount = icount + 1    
plt.show()

```

**（予測の事例）**

![imageJRL8-6-4](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-4.jpg)

QEU:FOUNDER ： “これは、モデルを使った予測の事例です。前回と同じです。”

D先生 ： “ここで見られる、「予測があっている、外れている」という理由がアテンション・マップでわかるんでしょうかねえ・・・。”

```python
# ------
# TEST PICTURESを抽出する
i = 0
sample_image = X_test[i]
sample_pred  = class_names[idx_pred[i]]
sample_actual = class_names[y_test[i]]
print("prediction:{}, actual:{}".format(sample_pred, sample_actual))

# ------
# アテンション・マップを生成する
#from vit_keras import vit, utils, visualize

attention_map = visualize.attention_map(model=model.layers[0], image=sample_image)

# Plot results
fig, (ax1, ax2) = plt.subplots(ncols=2)
ax1.axis('off')
ax2.axis('off')
ax1.set_title('Original')
ax2.set_title('Attention Map')
_ = ax1.imshow(sample_image)
_ = ax2.imshow(attention_map)

```

QEU:FOUNDER  ： “まずは、アテンション・マップの一発目です。残念ながら、以下のケースでは予測は外れだったようです。”

![imageJRL8-6-5](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-5.jpg)

QEU:FOUNDER ： “ちゃんと、花の部分を見てくれているんだけど、（予測を）外しましたね。残念・・・。”

C部長 : “そもそも、タンポポとヒマワリは間違えやすいですから・・・。”

![imageJRL8-6-6](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-6.jpg)

D先生 ： “これ(↑)なんかは、とてもビューティフルな例です。”

C部長 : “ちゃんと、アテンションが「ポイント」を見ているような感じですね。”

![imageJRL8-6-7](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-7.jpg)

C部長 : “これ（↑）も、コンピューターがヒマワリをとらえていますね！！”

QEU:FOUNDER ： “まあ、一応はそうだともいえるが、少しだけ**犬にも注意している**でしょ？ちょっと、それが気に食わないです。この傾向が拡大すると以下（↓）のようになります。”

![imageJRL8-6-8](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-8.jpg)

D先生 ： “これは「ギリギリ・セーフ」の事例か？アテンションは鳥に行ってはいるが、その鳥の特性にバラ(rose)に通じるものがあったので、結果としてバラと予測されているという・・・。”

![imageJRL8-6-9](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-9.jpg)

QEU:FOUNDER ： “この事例（↑）では、猫に思いっきり注意が言っていますね。

C部長 : “これは、「なぜ？」なんでしょうかね？””

D先生 ： “多分、**事前学習の中で猫の画像を学習している**からでしょう。”

QEU:FOUNDER ： “だから、事前学習がノイズになっている可能性があるんだよね。事前学習のモデルには、たくさんの種類のモノを学習してほしい反面、ノイズを出しては欲しくはない。ここが矛盾なんです。でも、C部長、製造業の製造部長として、**このようなノリ（判定結果+アテンション・マップ）で不良を検出できるとありがたいと思わない？**”

C部長 : “こんな自動検査機があれば、ものすごくありがたいです！！”

D先生 ： “自動検査機は、他のやり方でも作れるが、あえてViTを推している理由は、このアテンション・マップを簡単に描ける能力ですね。”

QEU:FOUNDER ： “もっというと、以前、我々はRT法を拡張してAttentionを生成できないかとトライしていたでしょ？あれは、このような図を簡単に出力できないかと考えているからです。”

D先生 ： “なるほど。FOUNDERは、RT法を改造してアテンション・マップを作成するプロジェクトをあきらめたんですか？”

QEU:FOUNDER ： “まだ、（RT法の発展を）あきらめてはいないよ。ただし、それを極めていくとRT法からどんどん外れることがわかっていますよ。今回の、ViTのプロジェクトは「解決のためのヒント」を得るためのものでもあるんです。”

C部長 : “そういう意味でも、ViTのプロジェクトを是非成功させてください！！”

QEU:FOUNDER ： “べつに（自動検査機）専門のベンダーに任せなくても、誰もが簡単に立ち上げて・使える外観検査機を開発することが小生の夢でもあります。**ベンダーに頼むのは百害あって一利だけ**です。まあ、一歩一歩開発を進めましょう。寄付をお願いします。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER  ： “次は、何をしようかな・・・。”

## ～ まとめ ～

QEU:FOUNDER ： “年末になって、**「たいへんなこと」**がつぎからつぎへと起こるねえ・・・。”

![imageJRL8-6-10](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-10.jpg)

C部長 : “あれ？この件って、短期的な問題？それとも、もっと長期的なもの？”

![imageJRL8-6-11](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-11.jpg)

D先生 ： “さあ・・・。”

### オッサン： 従業員の皆さんにはテレビを見てください。皆が同じように考えてください。
### オッサン：“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ。
### オッサン：私の使命はこの会社で終身雇用制を実現することにある。

QEU:FOUNDER ： “そこらへんは、ようわからんね。ただ、小生は、**「オッサンは偉大だった」**と日々かみしめています。まあ、記事の趣旨に敢て乗っかるとして、なんで「開発期間が短い」んでしょうね？”

[![MOVIE1](http://img.youtube.com/vi/au-8lhzgCUw/0.jpg)](http://www.youtube.com/watch?v=au-8lhzgCUw "我慢しても苦しい･･･もう無理、限界、辛い･･･これからの時代を生き抜く考え方。我慢して頑張っても損するだけの時代。安冨歩東大教授")

D先生 ： “そんなに無理せんでもいいのに・・・。”

![imageJRL8-6-12](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-12.jpg)

QEU:FOUNDER  ： “この問題の本質には**「コモディティ」**があるんじゃないんか？。”

C部長 : “いきなり何を？そもそもコモディティとは？””

![imageJRL8-6-13](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-13.jpg)

D先生 ： “辞典で調べてみました。FOUNDERの文脈でいうと、モデルチェンジ毎の値段（または売上）の上げ幅が少なくなる状況ですね。その極地が鉛筆のような状態です。消費者は鉛筆が短くなれば買うみたいに・・・。”

QEU:FOUNDER ： “開発時間がなぜ短くなるのか？小生のグラフを積分すればわかります。モデルチェンジ後の売り上げが昔よりも小さくなったとするでしょ？儲けるには、モデルチェンジの期間を短く、頻繁にキャンペーンを打つしかないんですよ。”

C部長 : “でも、むりやりモデルチェンジしてくれても、**「クルマの魅力」**がそんなに変わるのかな？”

D先生 ： “軽でしょ？軽の最大の魅力は燃費でしょ？”

QEU:FOUNDER ： “もっと早く**プラットフォームを変えるべき**だったんでしょうね。2つのオプションがあります。コモディティ化を受け入れて、ビジネスのプラットフォームを変えるか。それとも、車のプラットフォームを劇的に変えるか。EV化みたいに・・・。”

D先生 ： “本来は、**軽自動車という特殊な分野を持っているJ国こそ、EV化の先鞭をつけるべき**なんでしたよね。そういえば、最近H社はエンジンの開発をすでに諦めましたよね。・・・と、いうことは・・・。”
QEU:FOUNDER ： “燃費をよくするには、軽量化を進めるしかない。つまり、衝突安全性に危険側に触れるんだよね。これで、辻褄があった・・・。それにしても、なんでEV化しなかったんだろ・・・？ＥＶ化が2010年ぐらいに実現するのが現実的なじゃかったろうか・・・。”

C部長 : “あれ？ＥＶ化って環境にやさしいの？あんまり、実感がないなあ・・・。”

![imageJRL8-6-14](/2023-12-25-QEUR23_VTRANS5/imageJRL8-6-14.jpg)

D先生 ： “一回、世紀の大災害に遭ったJ国民はそう思うよね。だから、このままではＥＶ化は進まないとおもうよ。「NUCLEARにしかJ国の未来はない」と思っている限りは・・・。”

QEU:FOUNDER  ： “いろんな意味で、**すべてが「イクところまでいって」います**な。”


