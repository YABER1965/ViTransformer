---
title: 技術まとめ ～ SOART3メトリックスとViTを併用した外観検査自動機（ダブル・モード）
date: 2024-02-05
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## 技術まとめ ～ SOART3メトリックスとViTを併用した外観検査自動機（ダブル・モード）

### 【発明の名称】 
SOART3メトリックスとViTを併用した外観検査自動機

### 【技術分野】
**【０００１】**
本発明はコンピューターによる外観検査自動機に関するものです。

### 【背景技術】
**【０００２】**
画像判別用の機械学習ロジックは、すでに提案されており、多くの成果が挙げられています(図1)。なかでもCNN（Convolutional Neural Network:畳み込みニューラルネットワーク）は、高い判別能力が得られています。

**(図1:画像認識のコンペの歴史)**

![imageJRL8-21-1](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-1.jpg)

**【０００3】**
ただし、これらの画像判別で成功した技術(図2)を、そのまま外観検査による異常検出に使用した場合には必ずしも良い結果が得られるとは限りません。一方、最近では**Vision Transformer（以下ViT）**という技術が提案されており、この手法の方が**CNNよりも外観検査用に優れている可能性があります**。CNNは畳み込みを重ねて情報を集約した特徴ベクトルを作るため、個体判別に優れています(図3)。しかし、CNNは特徴が空間的に分離した場合には判別精度はよくありません(図4)。一方、ViTは自然言語処理から派生した技術であるので、そのような制限はありません。学術成果として論文になっている事例もあります(図5)。

**(図2: 画像認識の例)**

![imageJRL8-21-2](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-2.jpg)

**(図3: 畳み込みニューラルネットワークの構造)**

![imageJRL8-21-3](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-3.jpg)

**(図4:Vision Transformerの構造)**

![imageJRL8-21-4](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-4.jpg)

**（図5:学術成果の例）**

![imageJRL8-21-5](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-5.jpg)

**【０００４】**
そのほか、既述のCNNやViT以外にも多くの異常検出手法が提案されており、プリント基板の品質管理などの転写性のきわめて高い製品を中心に実用化されています。代表的な手法を挙げると以下の通りです。

- **画像差分法**
- **距離を計測する方法**
- **教師あり学習（ディープラーニング）**
※オートエンコーダ―(VAE)はディープラーニングと画像差分法の中間的手法と考えられます

### 【発明の概要】
### 【発明が解決しようとする課題】

**【０００５】**
CNNまたはViTのみで外観検査をすることは、ある程度は可能です。例えば、以下の農業の課題(図6)では、一部の画像の葉の枯れ具合が異常であると考えられます (図7)。

**（図6:異常検出の非常に原始的な事例）**

![imageJRL8-21-6](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-6.jpg)

**（図7: 葉の学習画像）**

![imageJRL8-21-7](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-7.jpg)

**【０００６】**
上記の豆の葉の病気判別の事例では、ViTモデルを使って異常（病気）を検出しています。さらに、ViTの場合には学習したモデルの情報から**アテンション・マップ**を生成することができ、異常の位置を発見することができます (図8)。

**（図8: 葉の異常検出、アテンション・マップ）**

![imageJRL8-21-8](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-8.jpg)

**【０００７】**
ただし、現実の製造現場に適用するにはCNNやViTの個体判別の技術をそのまま適用して異常判別することは難しくなります。現実の製造プロセスでは、前述の葉の検査の事例のように**画像に多様性はなく、製品の形状が欠陥部分を除きほとんど同じ**です。さらに、部品単位の検査の場合、**製品は単色**です(図9)。“

**（図9:製造現場の事例：プラスチック射出成型品）**

![imageJRL8-21-9](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-9.jpg)

**【０００８】**
また、製品欠陥は微小でも製品が不良になる場合が多く、高解像度(ex 1200x1200)の画像を使用して初めて検出できるものが多いです。しかし、CNNやViTの場合のように学習モデルを形成して予測する手法の場合には、モデルを成熟させるための学習データの準備コストと計算コストがより大規模になり、そのままでは品質管理への実用は難しい。その理由の一例を挙げると、ViTのモデルの事例では224x224などの小さな画像を使うことが多いです。この程度の大きさの画像では外観検査には向きません。逆に言えば、この入力画像の大きさの要求が、画像差分(VAE)などの画像をそのまま使う技術が、外観検査でいまだに使用される理由でもあります。


### 【課題を解決するための手段】

**【０００９】**
本発明では、上記の課題を解決するためにViTとSOART3合成画像処理を併用します。SOART3は、RT(Recognition Taguchi)法というタグチメソッドの技術の拡張です。RT法とは、標準ベクトルと計測ベクトルを比較し、Ｙ１（感度：β）とＹ２（SN比：η）の2つのメトリックスを生成します(図10)。

**（図10:RT法の原理）**

![imageJRL8-21-10](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-10.jpg)

**【００１０】**
SOART3法は、RT法を3次元メトリックス出力へ拡張させ、RGB画像を出力する手法です。RT法では、SN比として標準ベクトルと感度による補正後の計測ベクトルを比較したユーグリッド距離を使用しています。ここで、２つのベクトルの距離を普遍化して、**ミンコフスキー距離**を考えました(図11)。この距離はパラメタのｐ値を変化させることで、マンハッタン距離(p=0)～チェビシェフ距離(p=∞)まで変化することができます。つまり、SOART3法では、ユーグリット距離のかわりに2つの独立したメトリックスに分離させて3次元化したいので、マンハッタン距離とチェビシェフ距離を使っているのです(図12)。

**（図11:ミンコフスキー距離の定義）**

![imageJRL8-21-11](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-11.jpg)

**（図12:SOART法の考え方）**

![imageJRL8-21-12](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-12.jpg)

**【００１１】**
SOART3法の処理プロセスをPythonプログラムで記述した事例を示します。まずは、標準ベクトル(x)と計測ベクトル(y)のデータから感度（β）を計算します。その後、**xベクトルと感度で補正した計測ベクトルであるβyの間のチェビシェフ距離とマンハッタン距離をそれぞれ計算します**。チェビシェフ距離とマンハッタン距離は同じベクトル(x, βy)から生成しており、このままでは2つの距離には若干の相関があると思われるので、チェビシェフ距離は対数変換したあとでマンハッタン距離との差を取っています。対数変換は、**値の挙動を線形化し、学習モデルを小さくするために適用しています**。

```python
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # 感度(β)を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # チェビシェフ距離を計測
    vDistance = chebyshev(y,beta*x)

    # マンハッタン距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の対数変換
    log_beta  = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = math.log(vDistance+1.0) - log_yita
    
    return log_beta, log_yita, log_gamma

```

**【００１２】**
さらに、SOART3法は、**シングル・モード**（カメラ1台）でも、**ダブル・モード**（カメラ3台）でも使用できます(図13)。プリント基板や多色の印刷物の外観検査ではシングル・モードが有効であり、立体製品の検査ではダブル・モードが有効です。本発明では、ダブル・モードのみについて説明します。

**（図13:ダブル・モードの考え方）**

![imageJRL8-21-13](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-13.jpg)

**【００１3】**
ダブル・モードで立体感を計測できるのは、人類（動物）が複数の画像から距離感を測定するのと同じ原理です(図14)。

**(図14:ダブル・モードで立体感を得る原理)**

![imageJRL8-21-14](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-14.jpg)

**【００１４】**
ここでは、簡単にSOART3（ダブル・モード）の計算手法を使って合成画像を作成してみます。まずは、中央カメラで複数の製品画像を撮り、元のRGB値をグレースケール化して、それらの**平均画像**を生成します(図15)。

**(図15: 丸端子の標準データ、平均画像)**

![imageJRL8-21-15](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-15.jpg)

**【００１５】**
その後で、被検査品の左画像と右画像を同時に撮影し、それらを標準画像と同様にグレースケールに変換します(図16,17)。

**（図16:左カメラの画像）**

![imageJRL8-21-16](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-16.jpg)

**（図17:右カメラの画像）**

![imageJRL8-21-17](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-17.jpg)

**【００１６】**
これらの3枚の画像情報（ベクトル）を処理すると、SOART3メトリックスが得られます。**ダブル・モードでは、右カメラと左カメラのSOART3メトリックスの差を取ります**。その結果、以下のようなSOART3合成画像を生成できます（図18）。

**（図18: SOART3合成画像）**

![imageJRL8-21-18](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-18.jpg)


### 【実施例】

**【００１７】**
この実施例では、ワイヤーハーネスのコネクタ端子の外観検査への適用事例を紹介します。ワイヤーハーネスは電気製品内の多数の部品間を接続する電線群をまとめる部品（図19）であり、そのコネクタのピンの状態を外観検査する装置を開発します（図20）。

**(図19：ワイヤーハーネスとは)**

![imageJRL8-21-19](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-19.jpg)

**(図20: コネクタの端子検査)**

![imageJRL8-21-20](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-20.jpg)

**【００１８】**
本発明では、コネクタ内のピン異常判定のためにViTを使います。ここで今回の事例では、小規模なモデルを生成しました(図21)。

**(図21: 今回の実験で使用したViTモデル)**

![imageJRL8-21-21](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-21.jpg)

**【００１８】**
SOART3合成画像をつくるために、3CGソフト（Blender）の仮想空間上にコネクタを生成し、**右カメラ-中央カメラ-左カメラを設置**しました(図22)。そして、検出する不良モードは丸端子ピン（円柱）の垂直抜けとピンの傾きとしました(図23)。もちろん、ピンの不良はコネクタ内の各ピン位置で発生するものとします。このViTモデルを学習する段階では、その不良位置は1か所だけとします。

**(図22: 左-中央-右カメラの画像)**

![imageJRL8-21-22](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-22.jpg)

**(図23: 不良モードの定義)**

![imageJRL8-21-23](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-23.jpg)

**【００１９】**
まず最初に、丸端子をもつコネクタのみのデータを学習します。正常コネクタと不良コネクタを回転、シフト、光源エネルギーをばらつかせて撮影をしました(図24)。また、学習データにはSOART3合成画像だけでなく、撮影画像も使用しました。こうすることで、学習データ数がより多くなります。この単種端子のデータを学習したところ、その学習の過程で**ACCURACY（判別精度）が変化する進捗が遅い**という現象が見られました(図25)。

**（図24:学習データ：左右生画像と合成画像を含む）**

![imageJRL8-21-24](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-24.jpg)

**（図25:ViT学習の進捗）**

![imageJRL8-21-25](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-25.jpg)

**【００２０】**
ここで、学習を加速させる対策として別の端子種として角柱のCGモデルのデータを加えて学習します（図26）。この場合も、前述の円柱端子の場合と同様に、平均画像を作成し、SOART3処理を行います（図27）。

**（図26：角柱CGモデル）**

![imageJRL8-21-26](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-26.jpg)

**（図27：角柱端子のSOART3合成画像）**

![imageJRL8-21-27](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-27.jpg)

**【００２１】**
円柱端子と角柱画像を組み合わせて学習させたところ、Accuracyが変動を開始するEPOCHが前回よりもより早期になり、学習速度が単種よりもはやくなりました（図28）。つまり、端子種を増やしたことで、端子抜けは端子の形状に問わず、図形の移動と回転であることを、ViTモデルが理解したことが理由だと思われます。。

**（図28：丸端子と角端子を組み合わせた学習進捗）**

![imageJRL8-21-28](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-28.jpg)

**【００２２】**
さて、ViTモデルの学習の進捗に伴う、アテンションマップの変化について比較します（図29,30）。学習の初期は、アテンションが高い位置が欠陥の位置以外にも分布していました。それが学習の進展とともに、不良画像のときには欠陥位置にアテンションが集中します。一方、欠陥がないコネクタ画像の場合には、アテンションの分布が大きくばらつきます。

**（図29： 学習の初期段階～EPOCH:200）**

![imageJRL8-21-29](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-29.jpg)

**（図30： 学習の完了段階～EPOCH:600）**

![imageJRL8-21-30](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-30.jpg)

**【００２3】**
上記の学習が完了したモデルを使って、**検査画像の中に2か所に欠陥がある場合**のアテンションマップを生成した結果を紹介します。この場合でも、欠陥の2か所でのアテンションが高くなっています (図31、32)。

**(図31:  2か所に欠陥がある場合の画像)**

![imageJRL8-21-31](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-31.jpg)

**(図32:  2か所に欠陥がある場合のアテンション・マップ)**

![imageJRL8-21-32](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-32.jpg)

**【００２４】**
このように、SOART3+ViTによる外観検査は、外観検査の用途に対して非常に高いポテンシャルを有していると思います。その他、本発明では従来の判別モデルでは検出できないタイプの不良を発見ができます。端子の異品（例：本来は円形端子を使うはずだが、実際には角形をつかった）の場合には、通常の判別モデルでは良品としか判断しません。しかし、**SOART3では、標準画像と検査画像を比較して処理をしているので、その端子には異品欠陥があることがわかります**(図33,34)。例えば、下記の欠陥画像の場合、角端子の中に丸画像の影が含まれており、異品不良があることがわかります。

**(図33:  異品端子NO1)**

![imageJRL8-21-33](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-33.jpg)

**(図34:  異品端子NO2)**

![imageJRL8-21-34](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-34.jpg)

**【００２５】**
ただし、**ViTモデルを使用しているので、CNNモデルよりも大きな学習のためのデータ量が必要です**。そのため、一つのコネクタの外観検査のために、これほど大きなデータ量を準備するのはコスト的に不適切です。そのため、ディープラーニングの転移学習を応用したファイン・チューニングのためのシステム構築が不可欠と思われます(図35)。さらに、プレ・トレーニングで**CG画像を中心とした学習**を行い、ファイン・チューニングで現場画像の学習をするとコストを抑制できます。

**(図35: ファイン・チューニングの適用)**

![imageJRL8-21-35](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-35.jpg)

### 【産業上の利用可能性】

**【００２６】**
SOART3処理法を最近画像判別で高い評価を得ているViTモデルに適用すると、SOART3合成画像がViTモデルのもつ欠点を補完するため外観検査に広く応用できます。今回は、ダブル・モードについて紹介しました。シングル・モードとの比較は以下のようになり、それらの特徴は相反します。

**（ダブルモードの長所、特徴）**

- **立体品の画像を検出するのに優れている。**
- **カメラは3台（オフライン）、2台（オンライン）が必要**

**（シングルモードの長所、特徴）**

- **組立完成品や印刷物などのカラー画像を検出するのに優れている**
- **カメラは1台（オンライン）が必要である。ただし、オフライン時には多くのカメラがあったほうが望ましい。**

**（ダブル、シングルの共通長所）**

- **単一色の製品の検査画像でも、検査精度が高い。**
- **高い解像度(例：1000x100)の画像をSOART処理することで、情報量を落とさず低い解像度の画像(例：224ｘ224)に変換することができる。**
- **合成画像であるので、その入力がCG画像であっても実際の画像であっても、その学習する内容は変わらない。**

**【００２７】**
シングル・モードのSOART3合成画像の応用については、またの機会に説明します。


## ～ まとめ ～

### ・・・ 以下、発明の補足です ・・・

C部長: “すんません。ちょっと忘れてしまったので教えてください。今回発明のSOARTとはどういう由来なのですか？”

QEU:FOUNDER: “**「State-of-(the)-art のRT法」**という意味です。”

C部長: “**State-of-the-art(略称:SOTA)は「最先端」とか「現時点での最高パフォーマンス」**を指す言葉でしょ？アルファベットの「T」が足りないじゃないですか。”

QEU:FOUNDER: “だから、その肝心の（the）をカッコつけにしたわけ・・・。すなわち、RT法としては大幅に改良したとは思うが、**他のメトリックスに比較して特別に卓越したものではない**。だから「The(唯一)」の意味が抜けたんです。”

D先生: “なるほどねえ・・・。それでも、タグチ・メソッドが21世紀中盤にまで、とりあえず生き残る礎ができたのではないでしょうか。もともと、これから先に生き残る手法はパラメタ設計とT法（マハラノビス除く）だと考えていましたが・・・。”

![imageJRL8-21-36](/2024-02-05-QEUR23_VTRANS24/imageJRL8-21-36.jpg)

QEU:FOUNDER: “実際にはパラメタ設計(PD)の生き残りも難しいでしょ・・・。いっちゃ悪いが、パラメタ設計は、たかが「複数ある設計パラメタの最適化を図る」だけでしょう？世の中は、もうすぐさらに「その先」に行ってしまいます。”

[![MOVIE1](http://img.youtube.com/vi/-c-0JPCCRPE/0.jpg)](http://www.youtube.com/watch?v=-c-0JPCCRPE "生成AIの5年後、10年後：東京大学・今井翔太】5年後に肉体労働系AIが出現／洗濯物畳み、片付けロボ／10年後に研究が自動化／AIがノーベル賞受賞／超長期で人間も機械化")

D先生: “研究の自動化もできるのは大変なことですね。ただし・・・。”

QEU:FOUNDER: “モデル自体には人類をしのぐパワーがあります。問題は**ViTモデルを学習させるために十分なデータを「だれが提供するか」**ということですね。・・・ということで、もうしばらくは、（PDの優位性は）もつんじゃないですかね。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

D先生: “次は、(SOART3法の)シングル・モードの開発にうつりましょう。”

