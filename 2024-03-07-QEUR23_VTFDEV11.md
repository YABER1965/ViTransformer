---
title: QEUR23_VTFDEV11: プロダクションのためのテスト(STEP3B-可視化)
date: 2024-03-07
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VTFDEV11: プロダクションのためのテスト(STEP3B-可視化)

## ～ ビジュアル（可視化）、これが大事！！ ～

QEU:FOUNDER ： “さあて、いよいよ大詰めです。前回のSOART3プログラムで作成したCSVファイルを読み込み、RT（ミンコフスキー距離）を使って合成画像を作ります。このプログラムに入力するのは標準画像と・・・。”

![imageJRL9-12-1](/2024-03-07-QEUR23_VTFDEV11/imageJRL9-12-1.jpg)

D先生 ： “あと必要になるのは、「計測（比較）用の画像」です。前回のプログラムでは、昔のプロジェクトのネタを流用したいので、**「左カメラの画像」**を入力しました。あと、他にいうことはありますか？”

**（計測用の画像）**

![imageJRL9-12-2](/2024-03-07-QEUR23_VTFDEV11/imageJRL9-12-2.jpg)

**（計測画像は、「左カメラ」からとってきた）**

![imageJRL9-12-3](/2024-03-07-QEUR23_VTFDEV11/imageJRL9-12-3.jpg)

QEU:FOUNDER ： “ないと思うよ。プログラムをドン！！”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: Attention_map_via_SOARTC(PART2).py
# SOARTCのためにSOART3メトリックスを出力する
# ---------------------------------------------------
# モジュールのインポート
from fastai.vision.all import *
import pandas as pd
import numpy as np
from scipy.spatial.distance import chebyshev, minkowski

# -----
# メトリックスを3種に分類する
cols_beta = ["row", "col", "beta0", "beta1", "beta2", "beta3", 
            "beta4", "beta5",]
cols_yita = ["row", "col", "yita0", "yita1", "yita2", "yita3", 
            "yita4", "yita5",]
cols_gamma = ["row", "col", "gamma0", "gamma1", "gamma2", "gamma3", 
            "gamma4", "gamma5",]

#=================================================
# READ CSV FILES
#=================================================
# 画像CSVファイルを読み込み(分類して出力する)
def read_filecsv(file_readcsv): 
 
    # ---------------------------
    # 画像CSVファイルの読み込み
    df = pd.read_csv(file_readcsv) 
  
    return df

#=================================================
# LOOKUP METRICS from DataFrame
#=================================================
# データフレームからメトリックスを抽出する
def df_lookup(df, val_row, val_col): 
 
    # ---------------------------
    # データフレームの分割
    df_beta = df.loc[:, cols_beta]
    df_yita = df.loc[:, cols_yita]
    df_gamma = df.loc[:, cols_gamma]
    # ---
    temp_beta = df_beta.query(f'row == {val_row} & col == {val_col}')
    arr_beta = temp_beta.loc[:, "beta0":"beta5"].values
    # ---
    temp_yita = df_yita.query(f'row == {val_row} & col == {val_col}')
    arr_yita = temp_yita.loc[:, "yita0":"yita5"].values
    # ---
    temp_gamma = df_gamma.query(f'row == {val_row} & col == {val_col}')
    #     row  col  gamma0  gamma1  gamma2  gamma3  gamma4  gamma5
    #239    1    1     0.0     0.0     0.0     0.0     0.0     0.0
    arr_gamma = temp_gamma.loc[:, "gamma0":"gamma5"].values
    #print(arr_gamma)

    # ---------------------------
    # メトリックスをまとめる
    mx_metrics = [arr_beta.flatten(), arr_yita.flatten(), arr_gamma.flatten()]
 
    return mx_metrics

#=================================================
# 分析用の関数
#=================================================
# ----------------
# soaRTCメトリックス(no2)を計算する
def calc_soaRTC_no2(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # dot回転を計測
    #xx = np.dot(x,x) + 0.0001
    #xy = np.dot(x,y) + 0.0001
    #beta = xy/xx

    # チェビシェフ距離を計測
    #vDistance = chebyshev(y,beta*x)
    #vDistance = chebyshev(y,x)
 
    # ミンコフスキー距離を計測
    vDistance = minkowski(y, x, 4) #p=4 
 
    return vDistance

# ---------------- 
# Primitive image(beta, yita, gamma)を計算する
def calc_PrimImage(mx_standard, mx_measure): 

    # -----
    # データの分解
    # standard
    arr_standard_beta  = mx_standard[0]
    arr_standard_yita  = mx_standard[1]
    arr_standard_gamma = mx_standard[2]
    # measure
    arr_measure_beta  = mx_measure[0]
    arr_measure_yita  = mx_measure[1]
    arr_measure_gamma = mx_measure[2]
    # -----
    # SOART3メトリックスの計算
    # beta
    vDistance_beta = calc_soaRTC_no2(arr_standard_beta, arr_measure_beta)             
    # yita
    vDistance_yita = calc_soaRTC_no2(arr_standard_yita, arr_measure_yita)  
    # gamma
    vDistance_gamma = calc_soaRTC_no2(arr_standard_gamma, arr_measure_gamma)  
    # -----
    # とりまとめ
    arr_soartc = [round(vDistance_beta,5), round(vDistance_yita,5), round(vDistance_gamma,5)]
    #print("--- arr_soart ---")
    #print(arr_soart)

    return arr_soartc

#=================================================
# MAIN PROGRAM
#=================================================
# -----
# パラメタの設定
num_convX = 238
num_convY = 268
# -----
# 標準データベースの場合
filename_stadard = "soartc_part3_image_standard.csv"
df_standard = read_filecsv(filename_stadard)
# -----
# 計測データベースの場合
filename_measure = "soartc_part3_image_number1.csv"
df_measure = read_filecsv(filename_measure)

# ----------------
# SOARTCメトリックスの計算
mx_soartc = np.zeros([num_convY, num_convX, 3])
for val_row in range(num_convY):       # num_convY
    for val_col in range(num_convX):       # num_convX
        # -----
        # [STANDARD]メトリックスを抽出する
        mx_standard = df_lookup(df_standard, val_row, val_col)
        #print(gamma_standard)
        # -----
        # [MEASURE]メトリックスを抽出する
        mx_measure = df_lookup(df_measure, val_row, val_col)
        # -----
        arr_soartc = calc_PrimImage(mx_standard, mx_measure)          
        #print("val_row:{}, val_col:{}, arr_soartc:{}".format(val_row,val_col,arr_soartc))
        mx_soartc[val_row, val_col, :] = arr_soartc
# -----
#print("--- mx_soartc ---")
#print(mx_soartc[0:50,0:50,0])

#=================================================
# マトリックスを表示する
#=================================================
# -----
from PIL import Image
from scipy.special import softmax

#####################
# スケールの場合
#####################
# ---
# 値の規準化
max_red = np.max(mx_soartc[:,:,0])
max_green = np.max(mx_soartc[:,:,1])
max_blue = np.max(mx_soartc[:,:,2])
print(max_red, max_green, max_blue)

# ---
# 画像をarrayに変換
temp_RGB = np.asarray(mx_soartc[:,:,:])
temp_RGB[:,:,0] = temp_RGB[:,:,0]/max_red
temp_RGB[:,:,1] = temp_RGB[:,:,1]/max_green
temp_RGB[:,:,2] = temp_RGB[:,:,2]/max_blue
img_RGB = temp_RGB
#print(img_RGB)

# ------
# グラフ化
# ------
fig = plt.figure(figsize=(12,12))
fig.suptitle('assembled image: {}'.format(filename_measure))
# ---
ax1 = fig.add_subplot(1,1,1)
ax1.imshow(img_RGB)
#表示
plt.show()

```

QEU:FOUNDER ： “このようにプログラムを動かすと、まず最初にRGB画像が出力されます。”

**(RGB画像)**

![imageJRL9-12-4](/2024-03-07-QEUR23_VTFDEV11/imageJRL9-12-4.jpg)

D先生 ： “昔、我々がつくってきた、「(SOART3)ダブル・モード」の事例と比較してみましょう。以下のダブル・モードの写真（↓）は、アドレス3-1ピンの垂直端子抜けでした。今度の計測事例の画像は、どの部分に不良がありますか？”

**(ダブル・モードの事例)**

![imageJRL9-12-5](/2024-03-07-QEUR23_VTFDEV11/imageJRL9-12-5.jpg)


QEU:FOUNDER ： “今回の画像は、アドレス1-1の端子傾きです。まあ、両者は使った方法が違うので「見え方が違う」としか、現時点では言えませんね・・・。じゃあ、次にこれをグレースケール化しましょう。プログラムをドン”

```python
#####################
# グレースケール+softmaxの場合
#####################
# -----
max_images = num_convY*num_convX

# -----
# グレー・スケール
mx_GrayImg = np.zeros([num_convY, num_convX])
for i in range(num_convY):
    for j in range(num_convX):
        mx_GrayImg[i,j] = mx_soartc[i,j,0] + mx_soartc[i,j,1]*5.0 + mx_soartc[i,j,2]*10.0
# -----
# 値の規準化
max_gray = np.max(mx_GrayImg)

# ---
# 画像をarrayに変換
img_Gray = np.asarray(mx_GrayImg/max_gray)
print("---- グレー・スケールの生成 ----")
print(img_Gray)

# ------
# グラフ化
# ------
fig = plt.figure(figsize=(12,12))
fig.suptitle('assembled image: {}'.format(filename_measure))
# ---
ax2 = fig.add_subplot(1,1,1)
ax2.imshow(img_Gray)
#表示
plt.show()

```

D先生 ： “あらあら・・・、また変換式をいじりましたね・・・（笑）。じゃあ、この結果をみてみましょうか・・・。う～ん・・・、FOUNER・・・。RGB画像をグレースケールにしたメリットって何でしょうね。”

**(Gray Scale)**

![imageJRL9-12-6](/2024-03-07-QEUR23_VTFDEV11/imageJRL9-12-6.jpg)

QEU:FOUNDER ： “グレースケール化そのものには意味はないよ。これをもとにsoftmax関数に変換して初めて意味があるわけで・・・。”

**(SOFTMAX後)**

![imageJRL9-12-7](/2024-03-07-QEUR23_VTFDEV11/imageJRL9-12-7.jpg)

QEU:FOUNDER ： “コントラスト（メリハリ）がはっきりしてきただけですね（笑）。それでも、あまり重要でない線が消えたことにより、**画像中の異常を見やすくなった**といえます。本来はアドレス1-1ピンだけにスポットライトを当ててほしいが・・・。”

D先生 ： “それは無理です。今回は左カメラからの画像を使っているので、全部のピンに少しづつ差異が生まれてしまいます。ここまで異常が可視化されただけでも、とても素晴らしいものです。あっ、そういえば・・・、FOUNDER・・・。前回の終わりで「今回のプログラムには課題がある」と言っていましたが、何ですか？”

QEU:FOUNDER ： “ご存じの通り、今回のSOARTCメトリックスの計算は、**前回のSOART3の計算だけよりも計算量がやたら多くて時間がかかります**。もちろん、今回はテスト目的なので、わざわざpandasデータフレームをLOOKUPするような無駄なこともやっていますが・・・。まあ、とにかく、何らかの改善をしないと大量の画像処理には使えないよ。”

D先生 ： “それでは本件も延長ですね。プログラムの改善をして、他の事例の可視化もやってみましょう。”

QEU:FOUNDER  ： “基本的には、SOARTCは「（今後の）期待が持てるメトリックス」だとは思います。ただし・・・。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER  ： “ただし、これをたたき台にして、他の人たちが新たな提案をしてくれるともっとうれしいです。勝手に提案してください。小生には(提案を)いわんでもいいから・・・。ただし、こっそりカンパしてください。”


## ～ まとめ ～

QEU:FOUNDER ： “今回のSOARTCメトリックスの開発も、ついにマイルストーンにきましたね。さて、C部長は外観検査にSOART3を使うのが好き？それともSOARTCメトリックスが好きですか？”

C部長 : “それは、「（それらを）AIに適用する」という意味ですか？SOART3メトリックスでは大きなサイズの画像(ex 4000x4000)に適用しにくいですから、SOARTCメトリックスの方がいいでしょうね。ただし、SOARTCには、もう少し（計算が）速くなってくれないと困ります。 “

QEU:FOUNDER ： “速度UPでいちばんいい方法は、Pythonを捨ててJuliaでプログラムを組むことなんだが・・・。Cudaを使って高速化する方法はないものか・・・。”

C部長 : “ちょっと、シーズの調査しないといけないですね・・・。時代も進歩しているから、他にも方法はあると思うし・・・。“

QEU:FOUNDER ： “それはどもかく・・・。今回は、**「可視化のありがたみ」**を身に染みたわ・・・。”

![imageJRL9-12-8](/2024-03-07-QEUR23_VTFDEV11/imageJRL9-12-8.jpg)

C部長 : “「百聞は一見に如かず」ですね。”

QEU:FOUNDER ： “これを見て、何かが脳天から突き抜けるような衝撃を受けました。この先生（↑）には、**可視化ノーベル賞**を差し上げたい。もしも、そんなのがあるんだったらね。”

