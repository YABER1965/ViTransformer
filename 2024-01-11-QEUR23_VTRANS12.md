---
title: QEUR23_VTRANS12: Blenderでpythonを使って画像生成を自動化する
date: 2024-01-11
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VTRANS12: Blenderでpythonを使って画像生成を自動化する

## ～ プロジェクト後半のキックオフです ～

QEU:FOUNDER ： “それでは、これからがいよいよプロジェクトの後半です。いままでの成果としては、ViT(Visual Transformer)を使った異常検出法を確立したまでですね。”

![imageJRL8-13-1](/2024-01-11-QEUR23_VTRANS12/imageJRL8-13-1.jpg)

C部長 : “率直にいって、普通の人はここまでで満足していると思います。それでも、FOUNDERはさらに、**「もう一歩前へ」**進めるということですね。”

QEU:FOUNDER ： “そうです。それでは、久々にコレ（↓）をやりましょう。”

![imageJRL8-13-2](/2024-01-11-QEUR23_VTRANS12/imageJRL8-13-2.jpg)

D先生 ： “また、コネクタの端子抜け検査をするんですか？“

![imageJRL8-13-3](/2024-01-11-QEUR23_VTRANS12/imageJRL8-13-3.jpg)

D先生 ： “ちなみに、いわゆるコネクタの構造はコレ（↑）です。Blenderで描いているのは、いわゆる「オスのコネクタ」の形状です。このコネクタの中の端子の様子が正常か異常（不良）かを判定することが目標になります。なんか、久々ですね。**Blender(3Dレンダー)**をつかうのは・・・。“

QEU:FOUNDER ： “我々が昔使ったのはVer2.8あたりの頃です。現在は、バージョンが4.0まで行っています。”

C部長 : “Blenderの使い勝手は変わりましたか？”

QEU:FOUNDER ： “そんなに大きく変わっていないと思います。モタモタしているのは、小生が長い間、Blenderを使っていないだけのことであって・・・。しかし、Pythonプログラムによる制御に関するUIの使い勝手はかなり良くなったと思いますよ。おそらく、Blender-pythonは広くユーザーに受け入れられているのであろうと思います。さて、例の端子抜けの件に戻りますが、これは昔に説明したので重複になります。まずは、このプログラムから・・・。”

```python
# ====================
# シリンダ抜けのセッティングのプログラム
# ====================
# 端子を操作する
# cylinder_nuke.py
# bpyインポート
import bpy
import math

# ----
# 端子抜けのピンアドレスの初期設定
y_pin = 4  # 0-8
x_pin = 1  # 0-2

# ----
# 抜け位置の初期設定
dposX = 0       # 0
dposY = 0       # 0
dposZ = 0    # -0.5

# ----
# 抜け角度の初期設定
gradX = 0      # 20
gradY = 0      # 20
#gradZ = 0       # 0

# ----------
# 円柱のみを選んで削除する
def remove_items(arg_objectname):
 # 指定オブジェクトを取得する
 # (get関数は対象が存在しない場合 None が返る)
 selectob = bpy.data.objects.get(arg_objectname)

 # 指定オブジェクトが存在するか確認する
 if selectob == None:
  # 指定オブジェクトが存在しない場合は処理しない
  return False
 
 # 指定オブジェクトをアクティブに変更する
 bpy.context.view_layer.objects.active = selectob
 
 # 全てのオブジェクトを走査する
 for obj in bpy.data.objects:
  # メッシュオブジェクトか確認する
  if obj.type == 'MESH':
   # 指定オブジェクト以外のオブジェクトか確認する
   if arg_objectname in obj.name:   # 'p' in 'python'
   
    #print(obj.name)

    # 統合したオブジェクトを削除する
    bpy.data.objects.remove(obj)

 return True

# 円柱クリア関数を実行する
#remove_items("Cylinder")
remove_items("円柱")

# -------
# 円周率
vpi     = 3.1415

# ----------
# RGBを決める
r = 0.4
g = 0.8
b = 0.8

# 2.材質の定義(赤色)
mat1 = bpy.data.materials.new('hoge')
mat1.diffuse_color = (r, g, b, 1.0)

# 円柱列を生成する
for y in range(9):
 for x in range(3):
  bpy.ops.mesh.primitive_cylinder_add(radius=0.25, location=(x-1.0, y-4.0, 0))
  bpy.context.object.data.materials.append(mat1) # 材質(白)指定
  # 端子抜けを発生させる
  if y_pin == y and x_pin == x:
    # 図形を移動(dposX,dposY,dposZ移動)
    bpy.ops.transform.translate(value=(dposX,dposY,dposZ))    
    # 図形を回転(X軸周り)
    bpy.ops.transform.rotate(value=vpi*gradX/180 ,orient_axis='X')
    shiftY = math.sin(vpi*gradX/180)
    bpy.ops.transform.translate(value=(0,shiftY,0))   
    # 図形を回転(Y軸周り)
    bpy.ops.transform.rotate(value=vpi*gradY/180 ,orient_axis='Y')
    shiftX = math.sin(vpi*gradY/180)
    bpy.ops.transform.translate(value=(-shiftX,0,0))   

```

D先生 ： “確か、このプログラムはBlenderバーチャル空間における**「一部の端子の状態を変更するためのプログラム」**でした。プログラム中の端子番号と異常の状態を指示すれば、バーチャル空間で異常なコネクタを生成できます。 “

QEU:FOUNDER ： “次が3Dバーチャル空間の写真を連続して撮影するプログラムです。ドン・・・。”

```python
# ---------------------------
# Camera_pic_doubleEye.py 
# ===========================
# パラメタの初期化
# ===========================
import bpy
from mathutils import *
import math
import os
import random
import numpy as np
import pandas as pd

# ----------
# 円周率
vpi = 3.141592

# ラベル番号
num_label = 2

# フォルダ ラベルの定義
arr_dirname = ["NA"]*7
arr_dirname[0] = "NORMAL"
arr_dirname[1] = "31D05"
arr_dirname[2] = "41D05"
arr_dirname[3] = "31X10"
arr_dirname[4] = "41X10"
arr_dirname[5] = "31Y10"
arr_dirname[6] = "41Y10"

# tanshi positionの定義
arr_tslabel = ["NA"]*7
arr_tslabel[0] = "OK"
arr_tslabel[1] = "NUKE31NG"
arr_tslabel[2] = "NUKE41NG"
arr_tslabel[3] = "BEND31NG"
arr_tslabel[4] = "BEND41NG"
arr_tslabel[5] = "BEND31NG"
arr_tslabel[6] = "BEND41NG"


# ===========================
# カメラ・ライト関数群
# ===========================
# カメラのみを選んで削除し、再設置する
def reset_cameras(obj_cnt):

 # -----
 # remove existing cameras  
 bpy.ops.object.select_by_type(type='CAMERA')
 bpy.ops.object.delete()

 if obj_cnt < 5:

  # ===========================
  # ベース（原点） - 10回以下は厳密に原点狙い
  # ===========================
  # ランダム偏差量の設定
  diff_posX  = 0
  diff_posY  = 0
  datum_posZ = 14.0
  # -----
  diff_gradX = 0
  diff_gradY = 0
  diff_gradZ = 0

 else:

  # ===========================
  # ベース（原点） - 10回以上はランダムに外す
  # ===========================
  # ランダム偏差量の設定
  diff_posX  = round(random.random()*0.15 - 0.075,2)
  diff_posY  = round(random.random()*0.2 - 0.1,2)
  datum_posZ = 14.0
  # -----
  diff_gradX = round(np.arctan(diff_posX/datum_posZ),2)
  diff_gradY = round(np.arctan(diff_posY/datum_posZ),2)
  diff_gradZ = random.random()*0.5 - 0.25

 # ===========================
 # CAMERA LEFT
 # ===========================
 # 位置の初期設定
 posXL = 0 + diff_posX
 posYL = -1 + diff_posY
 posZL = 14.0

 # ----
 # 角度の初期設定
 gradXL = 0 + diff_gradX
 gradYL = round(-4.09*vpi/180,2) + diff_gradY
 gradZL = round((90.0+diff_gradZ)*vpi/180,2)

 # add new cameras  
 bpy.ops.object.camera_add(location=(posXL, posYL, posZL), rotation=(gradXL, gradYL, gradZL))
 bpy.context.object.data.name="camera_left"

 # ===========================
 # CAMERA CENTER
 # ===========================
 # 位置の初期設定
 posXC = 0 + diff_posX
 posYC = 0 + diff_posY
 posZC = 14.0

 # ----
 # 角度の初期設定
 gradXC = 0 + diff_gradX
 gradYC = 0 + diff_gradY
 gradZC = round((90.0+diff_gradZ)*vpi/180,2)

 # add new cameras  
 bpy.ops.object.camera_add(location=(posXC, posYC, posZC), rotation=(gradXC, gradYC, gradZC))
 bpy.context.object.data.name="camera_center"

 # ===========================
 # CAMERA RIGHT
 # ===========================
 # 位置の初期設定
 posXR = 0 + diff_posX
 posYR = 1 + diff_posY
 posZR = 14.0

 # ----
 # 角度の初期設定
 gradXR = 0 + diff_gradX
 gradYR = round(4.09*vpi/180,2) + diff_gradY
 gradZR = round((90.0+diff_gradZ)*vpi/180,2)

 # add new cameras  
 bpy.ops.object.camera_add(location=(posXR, posYR, posZR), rotation=(gradXR, gradYR, gradZR))
 bpy.context.object.data.name="camera_right"

 # ----
 # パラメタ引き渡し用のベクトル(L,C,R)
 arr_cameraL = [ posXL, posYL, posZL, gradXL, gradYL, gradZL ]
 arr_cameraC = [ posXC, posYC, posZC, gradXC, gradYC, gradZC ]
 arr_cameraR = [ posXR, posYR, posZR, gradXR, gradYR, gradZR ]

 return arr_cameraL, arr_cameraC, arr_cameraR

# ----------
# ライトのみを選んで削除し、再設置する
def reset_lights(obj_cnt):

 # ----
 # 位置の初期設定
 posXL = 4
 posYL = -0.2
 posZL = 6.0
 posXR = -4
 posYR = 0.2
 posZR = 6.0
 
 # ----
 # 角度の初期設定
 gradXL = 0.8*vpi/180
 gradYL = 32*vpi/180
 gradZL = 0
 gradXR = -0.8*vpi/180
 gradYR = -32*vpi/180
 gradZR = 0

 # remove existing light   
 bpy.ops.object.select_by_type(type='LIGHT')
 bpy.ops.object.delete()

 # locate area light
 # LEFT
 light_energyL = 300 + random.random()*200
 bpy.ops.object.light_add(type='AREA', location=(posXL, posYL, posZL), rotation=(gradXL, gradYL, gradZL))
 bpy.context.object.data.energy = light_energyL
 bpy.context.object.data.name="light_left"
 # RIGHT
 light_energyR = 300 + random.random()*200
 bpy.ops.object.light_add(type='AREA', location=(posXR, posYR, posZR), rotation=(gradXR, gradYR, gradZR))
 bpy.context.object.data.energy = light_energyR
 bpy.context.object.data.name="light_right"

 # パラメタ引き渡し用のベクトル
 arr_lightL = [ posXL, posYL, posZL, gradXL, gradYL, gradZL, light_energyL ]
 arr_lightR = [ posXR, posYR, posZR, gradXR, gradYR, gradZR, light_energyR ]

 return arr_lightL, arr_lightR
 
# ===========================
# シーンを連続して生成し、画像ファイルとして保存する
# ===========================
# リストの初期化
mx_temp = []

# ----------
# Sceneを指示
scene   = bpy.context.scene

# iteration count
i_cnt = 0

# Camera shot
for obj_cnt in range(20):

 # ------
 # カメラのみを選んで削除し、再設置する
 arr_cameraL, arr_cameraC, arr_cameraR = reset_cameras(obj_cnt)

 # パラメタ引き渡し用のベクトル
 camera_posX = round(arr_cameraC[0],2)
 camera_posY = round(arr_cameraC[1],2) 
 camera_posZ = round(arr_cameraC[2],2) 
 camera_gradX = round(arr_cameraC[3],2) 
 camera_gradY = round(arr_cameraC[4],2) 
 camera_gradZ = round(arr_cameraC[5],2) 

 # ------
 # ライトのみを選んで削除し、再設置する
 arr_lightL, arr_lightR = reset_lights(obj_cnt)
 
 # パラメタ引き渡し用のベクトル
 light_energyL = int(arr_lightL[6])
 light_energyR = int(arr_lightR[6])

 # ------
 cam_cnt = 0
 # ------
 # 画像の撮影
 for ob in scene.objects:
  #print( ob.name )
  if ob.type == 'CAMERA':
   bpy.context.scene.camera = ob
   #print('Set camera %s' % ob.name )
   print("TURN:{}, Camera NO:{}, Camera name:{}".format(i_cnt,cam_cnt,ob.name))
   # ----
   degX = int(camera_gradX*180/vpi)
   degY = int(camera_gradY*180/vpi)
   degZ = int(camera_gradZ*180/vpi)
   # ----
   # 撮影とファイル保存
   name_cam = "cam-era{0}_{1}_{2}_{3}_{4}_{5}_{6}_{7}".format(i_cnt,cam_cnt,light_energyL,light_energyR,degZ,camera_posX,camera_posY,arr_tslabel[num_label])
   name_cam = name_cam.replace('0.', '0')
   name_cam = name_cam.replace('-', 'm')
   name_cam = name_cam.replace('.', '')
   print("filename_camera:{0}".format(name_cam))
   filename_pics = "D:/camera_test/{0}/{1}".format(arr_dirname[num_label], name_cam)
   bpy.context.scene.render.filepath = filename_pics
   bpy.ops.render.render( write_still=True )

   # リストに追加する
   mx_temp.append([filename_pics, cam_cnt, degX, degY, degZ, camera_posX, camera_posY, light_energyL, light_energyR, arr_tslabel[num_label], arr_dirname[num_label]])
   cam_cnt  = cam_cnt + 1
 # --- 
 i_cnt = i_cnt + 1

# ----
# データフレームへの出力
df = pd.DataFrame(data=mx_temp, columns=['file_name', 'camNO', 'degX', 'degY', 'degZ', 'posX','posY', 'power_left','power_right', 'tslabel', 'dirname'])
print(df)

# ----
# CSVファイルへの出力
name_csv = "labels{0}_{1}.csv".format(num_label, arr_tslabel[num_label])
print("filename_label:{0}".format(name_csv))
filename_csv = "D:/camera_test/{0}/{1}".format(arr_dirname[num_label], name_csv)
df.to_csv(filename_csv)

```

QEU:FOUNDER ： “このプログラムを動かせば、連続して画像を出力できます。”

![imageJRL8-13-4](/2024-01-11-QEUR23_VTRANS12/imageJRL8-13-4.jpg)

D先生 ： “ほう・・・。今回は、**撮影用のカメラを3台設置**しましたね。そして、中央カメラが1番になると・・・。・・・となると、これからの展開は前回と同じ解析手法（SOART法）になるの？。”

C部長 : “どうなんです？”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER  ： “さあね。今、小生が言えるのは、**「寄付ください」**ということだけ・・・。”


## ～ まとめ ～

QEU:FOUNDER ： “プロジェクトの後半の最初になるので、ちょっと解説をしましょう。なぜ、我々が「後半に突入している」のかについて・・・。”

D先生 ： “普通の人だったら、前半で終わりでしょ。それでも、やっちゃう私たち・・・。”

**（レイヤー：0）**

![imageJRL8-13-5](/2024-01-11-QEUR23_VTRANS12/imageJRL8-13-5.jpg)

QEU:FOUNDER ： “まずは、前回のレイヤー別アテンションマップを見てみましょう。レイヤー０から・・・。”

D先生 ： “異常検出から見ると、アテンションは画像の全体を見ていて、（異常検出にとって）意味がない結果でしたね。”

![imageJRL8-13-6](/2024-01-11-QEUR23_VTRANS12/imageJRL8-13-6.jpg)

QEU:FOUNDER ： “現実の外観検査って、**豆の葉の健康度評価よりも異常度がはるかに低い**んですよ。”

D先生 ： “は？異常度とは？”

QEU:FOUNDER ： “例えば、2枚の画像があります。1枚は標準画像、もう一枚は検査対象の画像です。**外観検査すべき項目**が、その中に1000項目あります。そして、1項目だけ違っていれば不良品になりえます。その程度のお話・・・。”

D先生 ： “つまり、製品**転写性**の問題ですね。 “

**（レイヤー：1）**

![imageJRL8-13-7](/2024-01-11-QEUR23_VTRANS12/imageJRL8-13-7.jpg)

QEU:FOUNDER ： “高い転写性を前提としている製品の外観検査において、豆葉の健康検査（dataset:beans）と同じ方法を使うことに対して、少しだけ「躊躇」があるんです。・・・確かにね、データを膨大につぎ込めばモデルが適当に、「なんとかしてくれる」とは思いながらもね・・・。”

C部長 : “その気持ちわかります。**学習データが多くなっていく**ことへの懸念ですね。”
