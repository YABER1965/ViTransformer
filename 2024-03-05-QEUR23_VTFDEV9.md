---
title: QEUR23_VTFDEV9: 大きな画像を処理するためのテスト(STEP2A-複数の画像を処理する)
date: 2024-03-05
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VTFDEV9: 大きな画像を処理するためのテスト(STEP2A-複数の画像を処理する)

## ～ あと、もう一歩！！ ～

QEU:FOUNDER ： “前回のタスクで多様な図形のSOARTCメトリックスが作成されました。これをもとにして、**「より大きな画像」**を出力しましょう。”

**（多様な画像群）**

![imageJRL9-10-1](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-1.jpg)

**（SOARTCメトリックスのデータベース）**

![imageJRL9-10-2](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-2.jpg)

QEU:FOUNDER ： “今回、やろうとしていることは簡単。すでに作成した画像を縦横に貼り合わせて、より大きな画像にするだけです。”

![imageJRL9-10-3](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-3.jpg)

D先生 ： “ふ～ん、これで解析プログラムがより複雑になるの？”

QEU:FOUNDER ： “違う違う・・・。ただ、貼り付けた画像に対応するレコードをデータベースから呼び出して、SOARTメトリックスを積み上げるだけです。**今回のSTEP2の目的は、じつは別のところにあります**。それでは、プログラムをドン！！”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: combine_images_and_SOARTC.py
# 出来合いの画像イメージを結合して、対応したSOARTCメトリックスを出力する
# ---------------------------------------------------
# モジュールのインポート
from fastai.vision.all import *
import cv2
import random
import pandas as pd
import numpy as np
from scipy.special import softmax

# ----
# ファイル参照先
nam_dir = "./soartc/"
nam_subdir1 = "IMAGE/"
nam_subdir2 = "OUT_IMAGE/"

# -----
# メトリックスを3種に分類する
out_columns = ["filename", "shape", "size", "color", "rotation", "shiftX", "shiftY", "F_beta", "F_yita", "F_gamma"]

#=================================================
# READ CSV FILES
#=================================================
# 画像CSVファイルを読み込み(分類して出力する)
def read_filecsv(file_readcsv, val_shape): 
 
    # ---------------------------
    # 画像CSVファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ---------------------------
    # 出力するデータフレーム
    df_cut = df[df['shape'] == val_shape]
    df_out = df_cut.loc[:,out_columns]
  
    return df_out

# 画像CSVファイルを読み込み(分類して出力する)
def output_filecsv(filename, record_rectangles, record_triangles): 

    # ---------------- 
    # 画像CSVファイルを読み込み(分類して出力する)
    #filename = "soartc_part1_variety.csv"
    #print(filename)
    # ---
    # rectangle
    val_shape = "rectangle"
    df_temp = read_filecsv(filename, val_shape)
    df_rectangle = df_temp.iloc[record_rectangles,:]
    # ---
    # triangle
    val_shape = "triangle"
    df_temp = read_filecsv(filename, val_shape)
    df_triangle = df_temp.iloc[record_triangles,:]
    # ----
    #max_df = len(df)
    #print("--------")
    #print(df)
    
    return df_rectangle, df_triangle

# ============================
# 画像レコードとメトリックスを抽出する
# ============================
# -------------
# パラメタ設定(1)
max_variety = 37
max_row_images = 3
max_col_images = 3
max_images = max_row_images * max_col_images

# パラメタ設定(2)
max_triangles = 1
max_rectangles = max_images - max_triangles

# -------------
# 基本的な変数の設定
mx_imgNO = [["NA"]*max_col_images for i in range(max_row_images)]
print(mx_imgNO)
# ---
mx_RGBimg = np.zeros([max_row_images, max_col_images, 3])
print(mx_imgNO)

# -------------
# 抽出すべきレコードの設定
# rectangle(正方形)の場合
record_rectangles = []
for i in range(max_rectangles):
    val_random = random.randint(0,max_variety-1)
    record_rectangles.append(val_random)
# triangle（三角形）の場合
record_triangles = []
for i in range(max_triangles):
    val_random = random.randint(0,max_variety-1)
    record_triangles.append(val_random)
#print(record_rectangles)
#print("--------")
#print(record_triangles)

# -------------
# データを読み込む
filename_csv = nam_dir+nam_subdir2+"soartc_part1_variety.csv"
print(filename_csv)
df_rectangle, df_triangle = output_filecsv(filename_csv, record_rectangles, record_triangles)
#print(df_rectangle)
#print("--------")
#print(df_triangle)

# ============================
# マトリックス（行列）を作成する
# ============================
# -----
files_rectangle = df_rectangle.loc[:,'filename'].values
files_triangle = df_triangle.loc[:,'filename'].values
#print(files_rectangle)
# -----
mx_Y_rectangle = df_rectangle.loc[:,['F_beta','F_yita','F_gamma']].values
mx_Y_triangle = df_triangle.loc[:,['F_beta','F_yita','F_gamma']].values
#print("---------")
#print(mx_Y_rectangle)

# -------------
# ファイル名行列を生成する
rect_cnt = 0
tri_cnt = 0
for i in range(max_row_images):
    for j in range(max_col_images):
        if i == 1 and j == 1:
            mx_imgNO[i][j] = files_triangle[tri_cnt]
            tri_cnt = tri_cnt + 1
        else:
            mx_imgNO[i][j] = files_rectangle[rect_cnt]
            rect_cnt = rect_cnt + 1 
# -----
print(mx_imgNO)

# -------------
# RGBマップを生成する
rect_cnt = 0
tri_cnt = 0
for i in range(max_row_images):
    for j in range(max_col_images):
        if i == 1 and j == 1:
            mx_RGBimg[i,j,:] = mx_Y_triangle[tri_cnt,:]
            tri_cnt = tri_cnt + 1
        else:
            mx_RGBimg[i,j,:] = mx_Y_rectangle[rect_cnt]
            rect_cnt = rect_cnt + 1 
# -----
print(mx_RGBimg)

```

QEU:FOUNDER ： “今回の目的は、実は**「変換式の定義」**と**「softmaxの適用」**にあります。”

```python
# -------------
# RGB をグレースケールに変換する
# https://algorithm.joho.info/image-processing/rgb-to-gray-color-space/
# RGBカラー画像をグレースケール画像に変換する場合は以下の式を利用します。
# Gray = Red * 0.3 + Green*0.59 + Blue*0.11
# -----
# 変換式を変えましょう！（理由）
# beta: 図形の回転  -> x 1.0
# yita: 図形(blob)の差異 -> x 2.0
# gamma: blobの、より高次の差異 -> x 3.0
mx_GrayImg = np.zeros([max_row_images, max_col_images])
for i in range(max_row_images):
    for j in range(max_col_images):
        #mx_GrayImg[i,j] = mx_RGBimg[i,j,0]*0.3 + mx_RGBimg[i,j,1]*0.59 + mx_RGBimg[i,j,2]*0.11
        mx_GrayImg[i,j] = mx_RGBimg[i,j,0] + mx_RGBimg[i,j,1]*2.0 + mx_RGBimg[i,j,2]*3.0
# -----
print("---- スケールの生成 ----")
print(mx_GrayImg)

# -------------
# Softmaxを適用する
# -----
mx_probImg = softmax(mx_GrayImg*max_images**0.5)
print("---- softmaxに変換した ----")
print(mx_probImg)

```

QEU:FOUNDER ： “それでは解析結果をみてみましょう。さっきの画像をSOARTCメトリックスに変換にしました。そして、それをさらにsoftmax関数で変換しました。”

![imageJRL9-10-4](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-4.jpg)

D先生 ： “softmax関数で処理すると、異常の位置が明確に出てきますね。そういえば、Transformerで使うAttentionって、softmax関数を使っていましたよね。”

![imageJRL9-10-5](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-5.jpg)

D先生 ： “あとsoftmax関数の件でいうと、なぜ、**このプログラムではスケールに画像数の平方根をかけている**んですか？”

QEU:FOUNDER ： “プログラムを開発しているとき、おもわず、むかし習ったマハラノビス距離のことを思い出したんです。”

![imageJRL9-10-6](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-6.jpg)

QEU:FOUNDER ： “マハラノビス距離を異常検出に適用する場合、入力する項目数が多くなればなるほどしきい値が大きく成ります。**これをカイ二乗分布でいうと、そのしきい値の値は項目数の平方根に比例する**そうな・・・。そのアイデアを使ったんですよ。この考え方がないと、大きな画像に対応できないですよ。”

![imageJRL9-10-7](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-7.jpg)

D先生 ： “なるほど、現場の外観検査で異常があるのは画像の一部分だけです。あとは正常です。そうなると、画像が大きくなればなるほど、異常部分を検出するのは困難になります。この補正のやり方が正しいのかはさておき、ある種の補正は重要です。あと、あの妙なグレースケール変換式の件ですが・・・。”

**（図形の回転と移動）**

![imageJRL9-10-8](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-8.jpg)

**（図形の大きさと色）**

![imageJRL9-10-9](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-9.jpg)

QEU:FOUNDER ： “これは、小生が前回の解析結果を眺めて、気軽に考えてみた結果です。さて、**「①：回転と移動(X,Y)」**、**「②：図形形状の差異」**、**「③：より高次の異常」**を比較したときには、どれが比較的重要でないのか？”

D先生 ： “①の「回転」はそれほど重要じゃないでしょう。あと、③の「より高次の異常」って、現場で検査をする場合には重要になってきますよね。”

QEU:FOUNDER ： “だから、ああいう式になりました。もちろん、その係数の設定には異論はあるとは思うが・・・。”

D先生 ： “なるほど。”

```python
from PIL import Image

#画像の読み込み
arr_images = []
for i in range(max_row_images):
    for j in range(max_col_images):
        tempname = mx_imgNO[i][j].replace('.csv','.jpg')
        imgname = tempname.replace('/INPUT','/IMAGE')
        #print(imgname)
        # 画像の読み込み
        im = Image.open(imgname)
        # 画像をarrayに変換
        im_list = np.asarray(im)
        # 累積
        arr_images.append(im_list)
# グラフ化
#fig,ax = plt.figure(figsize=(12,12))
fig, ax = plt.subplots(max_row_images, max_col_images)
fig.suptitle('assembled image')
# ---
icnt = 0
for i in range(max_row_images):
    for j in range(max_col_images):
        ax[i][j] = fig.add_subplot(max_row_images, max_col_images, icnt+1)
        ax[i][j].imshow(arr_images[icnt])
        # X軸とY軸を完全に非表示にする
        #ax[i][j].axes.xaxis.set_ticklabels([])
        #ax[i][j].axes.yaxis.set_ticklabels([])
        icnt = icnt + 1
#表示
plt.show()

```

QEU:FOUNDER ： “ついでに他のケースもみてみましょう。上のプログラムで組み合わせた画像と比較してみましょう。”

**（入力画像その１）**

![imageJRL9-10-10](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-10.jpg)

**（解析結果その１）**

![imageJRL9-10-11](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-11.jpg)

D先生 ： “中央と周辺のスケール値の差異は少しですが、これをsoftmax関数で処理すると**大きな差**がでてきますね。”

**（入力画像その２）**

![imageJRL9-10-12](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-12.jpg)

**（解析結果その２）**

![imageJRL9-10-13](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-13.jpg)

QEU:FOUNDER ： “おやおや・・・。中央の三角形に注意（attention）が向かなくなりました。。”

D先生 ： “回転と移動によって、枠から外れて四角形の角が欠けてしまいました。このタイプの異常だと、標準図形（正方形）であるにもかかわらず異常度があがるんですよね。あっ！私、発見しました。**このやり方を使うと、transformerを使わずともattentionマップをつくれる**んじゃないですか？”

![imageJRL9-10-14](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-14.jpg)

QEU:FOUNDER ： “そう・・・。それが、今回のプロジェクトの目的です。さて、いよいよ山場です。カンパをください。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER  ： “次はプロダクション(実際にやってみる)、STEP3の段階です。”


## ～ まとめ ～

### ・・・ つづきです ・・・

QEU:FOUNDER ： “怒られるよ。この人（↓）に・・・。”

[![MOVIE1](http://img.youtube.com/vi/BxocTCzgJyo/0.jpg)](http://www.youtube.com/watch?v=BxocTCzgJyo "【朝日新聞報道の大問題】日本の皆さんの給料、なぜ上がらないのか完全解説【菅野完氏 政治解説切り抜き】")

C部長 : “やめて～！！**公務員の給料「も」あげましょう～！**“

QEU:FOUNDER ： “とくにこの自治体（↓）はね。”

![imageJRL9-10-15](/2024-03-05-QEUR23_VTFDEV9/imageJRL9-10-15.jpg)

C部長 : “あそこ、へんなことばかりやっているし・・・。”

[![MOVIE2](http://img.youtube.com/vi/0rzwyWzLxhs/0.jpg)](http://www.youtube.com/watch?v=0rzwyWzLxhs "止めなあかん！お笑い大阪維新万博～リング・ペット・トイレ！（西谷文和さん）")

QEU:FOUNDER ： “あれ・・・。必要なのかな？”

C部長 : “もう、やめちゃえ！”

[![MOVIE3](http://img.youtube.com/vi/RZRnXkDmhyk/0.jpg)](http://www.youtube.com/watch?v=RZRnXkDmhyk "【梅門官方】李鳳山師父平甩教學30min")

QEU:FOUNDER ： “まあまあ、リラックスしてください。もうすぐ、お手手ブラブラさせても外観検査ができる時代が来るわけだし・・・。”

