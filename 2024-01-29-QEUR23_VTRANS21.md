---
title: QEUR23_VTRANS21:  ViTモデルを端子種類をミックスしたデータで学習する（前回からつづく）
date: 2024-01-29
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VTRANS21:  ViTモデルを端子種類をミックスしたデータで学習する（前回からつづく）

## ～ 何はともあれ、効果の確認は大事です ～

### ・・・ 前回のつづきです ・・・


A係長 ： “じゃあ、次はコネクタを変えて学習してみましょう！”

B係長 ： “う～ん、残念・・・。さっき、FOUNDERから、是非やって欲しいと言われているデータの学習があるので、それのトライアルが終わってからやりましょう。”

A係長 : “へえ・・・。FOUNDERは、どんなデータを送ってくれたんですか？”

![imageJRL8-22-1](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-1.jpg)

B係長 ： “こんな感じ（↑）の**「（角柱と円柱の）ミックス」端子配列**のモノです。このような端子の形状を変えたものを学習して、はたして「さらなるパフォ―マンスの向上」が認められるかを検証させておきたいよね。”

A係長 : “その考え方だったら、三角形の端子を使ってもいいんじゃないと思いますが・・・。”

B係長 ： “FOUNDERは、今、手元にあるBlender-Pythonのプログラムで簡単に作れるものを考えていたんです。それでは、端子配列用のプログラムをドン！！”

```python
# ====================
# シリンダ抜けのセッティングのプログラム(Housing version)
# ====================
# 端子を操作する
# cylinder_nuke.py
# bpyインポート
import bpy
import math

# ----
# 端子抜けのピンアドレスの初期設定
y_pin = 2  # 0-8
x_pin = 1  # 0-2

# ----
# 抜け位置の初期設定
dposX = 0       # 0
dposY = 0       # 0
dposZ = 0    # -0.5

# ----
# 抜け角度の初期設定
gradX = 0      # 20
gradY = 0      # 20
#gradZ = 0       # 0

# ----------
# 円柱のみを選んで削除する
def remove_items(arg_objectname):
 # 指定オブジェクトを取得する
 # (get関数は対象が存在しない場合 None が返る)
 selectob = bpy.data.objects.get(arg_objectname)

 # 指定オブジェクトが存在するか確認する
 if selectob == None:
  # 指定オブジェクトが存在しない場合は処理しない
  return False
 
 # 指定オブジェクトをアクティブに変更する
 bpy.context.view_layer.objects.active = selectob
 
 # 全てのオブジェクトを走査する
 for obj in bpy.data.objects:
  # メッシュオブジェクトか確認する
  if obj.type == 'MESH':
   # 指定オブジェクト以外のオブジェクトか確認する
   if arg_objectname in obj.name:   # 'p' in 'python'
   
    #print(obj.name)

    # 統合したオブジェクトを削除する
    bpy.data.objects.remove(obj)

 return True

# 立方体柱クリア関数を実行する
remove_items("立方体")
remove_items("円柱")

# ----------
# 円周率
vpi     = 3.1415

# ----------
# RGBを決める
r = 0.4
g = 0.8
b = 0.8

# 2.材質の定義(赤色)
mat1 = bpy.data.materials.new('hoge')
mat1.diffuse_color = (r, g, b, 1.0)

# 円柱列を生成する
for y in range(9):
 for x in range(3):

  # ---
  if x == 1 and y%3 == 0: 
   #円柱の描画
   bpy.ops.mesh.primitive_cylinder_add(radius=0.25, location=(x-1.0, y-4.0, 0))
   bpy.context.object.data.materials.append(mat1) # 材質(ほぼ白?)指定
  elif x != 1 and (y+1)%3 == 0: 
   #円柱の描画
   bpy.ops.mesh.primitive_cylinder_add(radius=0.25, location=(x-1.0, y-4.0, 0))
   bpy.context.object.data.materials.append(mat1) # 材質(ほぼ白?)指定
  else:
   #立方体の描画
   bpy.ops.mesh.primitive_cube_add(location=(x-1.0, y-4.0, 0), size=0.5, rotation=(0, 0, 0))    #図形を変形(X方向2倍、Y方向1倍、厚さ方向4倍)
   bpy.ops.transform.resize(value=(1.0,1.0,4))
   #図形を移動(Z軸方向に 5移動)
   bpy.ops.transform.translate(value=(0,0,0))
   #色をつける
   bpy.context.object.data.materials.append(mat1) #

  # ---
  # 端子抜けを発生させる
  if y_pin == y and x_pin == x:
    # 図形を移動(dposX,dposY,dposZ移動)
    bpy.ops.transform.translate(value=(dposX,dposY,dposZ))    
    # 図形を回転(X軸周り)
    bpy.ops.transform.rotate(value=vpi*gradX/180 ,orient_axis='X')
    shiftY = math.sin(vpi*gradX/180)
    bpy.ops.transform.translate(value=(0,shiftY,0))   
    # 図形を回転(Y軸周り)
    bpy.ops.transform.rotate(value=vpi*gradY/180 ,orient_axis='Y')
    shiftX = math.sin(vpi*gradY/180)
    bpy.ops.transform.translate(value=(-shiftX,0,0))   

```

A係長 : “確かに、簡単なプログラムの改造ですね。あとは、同じ手順でSOART合成画像群がえられます。システム・アドミの担当のボクがやってみました。”

![imageJRL8-22-2](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-2.jpg)

A係長 ： “ミックス端子の標準画像をベースにしているので、画像の「変わり映え」がしないです。・・・なんというか、その「変わらなさ」がSOART3メトリックスの魅力ですね。ただし、この画像の変化はViTにとっては「大きな変化」なのかもしれません。”

B係長 : “ただし、ViT君は、大丈夫だと思うよ。Vision TransformerはCNNのようにこの手の画像の処理は苦手ではないから・・・。”

[![MOVIE2](http://img.youtube.com/vi/N2BlDPI8aJo/0.jpg)](http://www.youtube.com/watch?v=N2BlDPI8aJo "トランスフォーマー（ViT）の中身 ~ Multi-Head Attentionを画像処理で解説 ~")

B係長 ： “画像中に円柱がばらついて配置していても、ViTは問題なく認識してくれます。このViTの特徴こそが、**ViTがCNNよりも外観検査に向いている理由**です。”

![imageJRL8-22-3](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-3.jpg)

B係長 : “CNNは畳み込みを何回も続けることによってデータを圧縮して、特徴化しています。このような手法は、**「個体の識別」で特に高い性能を発揮**します。”

![imageJRL8-22-4](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-4.jpg)

B係長 ： “2010年代の画像認識のコンペティションは「個体判別（画像中の動物の分類など）」で行われたのです。CNNは個体判別に強い手法だったので、折よく、その実力を発揮できたんですね。”

![imageJRL8-22-5](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-5.jpg)

A係長 ： “なるほどね。逆に言うと、**「CNNは（特徴がばらつく）異常検査の手法としてはどうかな？」**という問いかけになります。それでは、ViTモデルの学習に移りましょう。”

![imageJRL8-22-6](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-6.jpg)

A係長 ： “若干だけだけど、Accuracyの値が変動し始めるEpochが速くなりました。・・・ただし・・・。”

B係長： “ただし・・・？”

![imageJRL8-22-7](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-7.jpg)

A係長 : “**最終的なパフォーマンスはあまり変わらない**と思います。大体、正解率は86％ぐらいです。それにしても、学習するデータの量が多くなってきたので、**学習速度が落ちた**なぁ・・・。”

![imageJRL8-22-8](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-8.jpg)

B係長 : “もうそろそろ、**「データの断捨離」**が必要だと思うよ・・・。今まで、データを増やすために生画像のデータ（↑）をそのまま学習していたでしょう？これらの画像は、それほど必要じゃないんじゃない？あくまで、我々は「円柱端子の合成画像を学習」したいのだから・・・。”

A係長 ： “じゃあ、次の機会でデータを少し減らしましょう。それでは、お待ちかねの**アテンション・マップ**です。結論からいうと、前回とは目立った差異はないので、学習回数(Epoch)を変えたときのアテンション・マップを見てみましょう。”

**（学習エポック数：300）**

![imageJRL8-22-9](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-9.jpg)

B係長 ： “おっと、その比較は面白い！300回の学習では、アテンションが強い位置は画面上に多数見えますね。これがどうなるのか・・・。”

**（学習エポック数：400）**

![imageJRL8-22-10](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-10.jpg)

A係長 ： “2つの画像を比較すると、同じ画像を入力していますね。アテンションが強い位置が少なく、しかも**徐々に正確な位置にシフト**してきています。もちろん、いまだにハウジングにアテンションが強くなるケースが多々ありますが・・・。”

**（学習エポック数：500）**

![imageJRL8-22-11](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-11.jpg)

B係長 ： “意外と学習とともに、アテンションの位置は動くんですね。これは、ちょっとした発見でした・・・。逆に言うと、アテンション・マップを見ることによって、どのような学習データを追加すべきかのヒントが得られますね。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

A係長  ： “次は、「（コネクタ）ハウジング」の形状を変えた学習データを使ってみましょう。”



## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

C部長 : “あれ？このカンフー（↓）を見たときがないですね。”

[![MOVIE2](http://img.youtube.com/vi/RZRnXkDmhyk/0.jpg)](http://www.youtube.com/watch?v=RZRnXkDmhyk "李鳳山師父平甩教學30min")

QEU:FOUNDER ： “TW発祥の、もっともシンプルなカンフーです。発案者は、**「近年の人間は複雑なことをし過ぎるから生命力が落ちてしまっている。私は、簡単な健康増進法を提案して人々の生命力を上げたい。」**と言ったんです。SOART3-ViTのコンセプトは、このカンフーと同じですよ。”

D先生 ： “このカンフーがJ国に100％普及したらどうなるでしょうか？ “

QEU:FOUNDER ： “J国のGDPが少なくとも1％上がります。これは、とても簡単な道理です。**年配の方々が健康になって、より多くの消費をすればGDPが上がる**でしょ？ “

[![MOVIE3](http://img.youtube.com/vi/N5sJFpC-ftw/0.jpg)](http://www.youtube.com/watch?v=N5sJFpC-ftw "トンデモ？本気？竹中平蔵の経済学。日本人は劣化した！自分が大臣の頃は良かった。失われた30年なんてない！竹中さんそこまで言っていいの？")

C部長 : “GDPを上げるには長時間労働をすればいいんだろうと思いました。”

![imageJRL8-22-12](/2024-01-29-QEUR23_VTRANS21/imageJRL8-22-12.jpg)

QEU:FOUNDER ： “（人々が）疲れて、生命力が落ちるだけです。**単純な認識作業では、むしろコンピューターが優れている時代が来る**んですよ。”

