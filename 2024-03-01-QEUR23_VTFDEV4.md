---
title: QEUR23_VTFDEV4:  SOARTCメトリックスとは何か(STEP1C-SOARTCのPART1)
date: 2024-03-01
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VTFDEV4:  SOARTCメトリックスとは何か(STEP1C-SOARTCのPART1)

## ～ いままでのアプローチとは少しちがうよ・・・。 ～

QEU:FOUNDER ： “さて、いよいよSOART3処理を行います。”

![imageJRL9-5-1](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-1.jpg)

D先生 ： “例によって、前回に準備した画像群(↓)を使うんですか？”

![imageJRL9-5-2](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-2.jpg)

QEU:FOUNDER ： “そうですよ。えっと、畳み込み部品は、昔のものから少しだけ変えています。”

![imageJRL9-5-3](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-3.jpg)

D先生 ： “畳み込み部品のサイズをこんなに大きくしたの！？う～ん、いまあるCSV画像ファイル（サイズ：11x11）をそのまま使ってSOARTC処理をするにはそうするしかないか・・・。”

**(前回使ったCSV画像)**

![imageJRL9-5-4](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-4.jpg)

QEU:FOUNDER ： “この画像（↑）は、予備実験のSOART3処理で使っていたものです。今回のSOARTCメトリックスでは、画像サイズをもっと大きくしないといけないです。”

**(今回使うCSV画像)**

![imageJRL9-5-5](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-5.jpg)

D先生 ： “あっ、そうか・・・。画像マトリックスを類似度行列に変換するんですよね。この画像（↑）によると、畳み込みの後に2x2のマリックスになります。”

QEU:FOUNDER ： “それでは、SOARTCの「上：PART1」を計算してみましょう。β、η、そしてγの3つのメトリックスが出力されます。それではプログラムをドン！！”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: metrics_via_SOARTC(PART1).py
# SOARTCのためにSOART3メトリックスを出力する
# ---------------------------------------------------
# モジュールのインポート
from fastai.vision.all import *
import pandas as pd
import numpy as np
from scipy.spatial.distance import chebyshev

# ----
# ファイル参照先
nam_dir = "./soartc/"
nam_subdir1 = "IMAGE/"
nam_subdir2 = "INPUT/"
nam_subdir3 = "SOARTC_CONV/"
nam_subdir4 = "OUTPUT/"

#=================================================
# READ CSV FILES
#=================================================
# 画像ファイルを読み込み
def read_imagecsv(file_readcsv): 
 
    # ---------------------------
    # 画像ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ---------------------------
    # イメージXs
    mx_Xs = df.loc[:,"col1":"col22"].values
  
    return mx_Xs

# ---------------- 
# 畳み込み部品パターンファイルを読み込み
def read_partscsv(file_readcsv): 
 
    # ---------------------------
    # 畳み込み部品パターンファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ---------------------------
    # イメージXs
    mx_Xs = df.loc[:,"col1":"col11"].values
  
    return mx_Xs

# ---------------- 
# 畳み込み処理を実施する関数
def apply_kernel(kernel, mx_tensor):
    return (mx_tensor * kernel).sum()

# ---------------- 
# データ範囲を切り出すための関数
def cut_DataArea(str_idx, str_col, max_cnv_idx, max_cnv_col, mx_signal):
    return (mx_signal[str_idx:str_idx+max_cnv_idx,str_col:str_col+max_cnv_col])

# ----------------
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array
    #print(y)
    #print(x)

    # dot回転を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # チェビシェフ距離を計測
    vDistance = chebyshev(y,beta*x)

    # 絶対値（マンハッタン）距離を計測
    mDistance = np.linalg.norm(y - beta*x, ord=1)
    #print("mDistance: ", mDistance.item())
    
    # 値の変換
    log_beta  = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = math.log(vDistance+1.0) - log_yita
    
    return log_beta, log_yita, log_gamma

# ---------------- 
# Primitive image(beta, yita, gamma)を計算する
def calc_PrimImage(arr_standard, arr_measure): 

    # SOART3メトリックスの計算
    beta, yita, gamma = calc_soaRT3(arr_standard, arr_measure)             
    # -----
    #print("--- layer:0 ---")
    #print(mx_soart[100:120,100:120,0])

    arr_soart = [round(beta,5), round(yita,5), round(gamma,5)]

    return arr_soart

#=================+================================
# MAIN PROGRAM : 画像ファイルを読み込む、パラメタを指定する
#=================================================

max_cnv_parts = 7

# ---------------- 
code_cnv_input = ['NA']*max_cnv_parts
code_cnv_input[0] = 'BEND1'
code_cnv_input[1] = 'BEND2'
code_cnv_input[2] = 'BEND3'
code_cnv_input[3] = 'BEND4'
code_cnv_input[4] = 'LINE1'
code_cnv_input[5] = 'LINE2'
code_cnv_input[6] = 'DATUM'
print(code_cnv_input)

# ---------------- 
# 畳み込み部品のサイズ
max_cnv_idx = 11
max_cnv_col = 11
# ---------------- 
# 計測位置の定義
arr_str_idx = [0,11]
arr_str_col = [0,11]
# ---------------- 
# RT行列のサイズ
max_rtm_idx = 2
max_rtm_col = 2

###################################
# 畳み込みを生成する
###################################

# 畳み込み用部品(7種類)を読み込む
for i_cnv in range(max_cnv_parts):    # max_cnv_parts
    # -----
    # 畳み込みファイル
    file_cnv_input = nam_dir + nam_subdir3 + code_cnv_input[i_cnv] + ".csv"  # ファイルパス名の生成 
    print(file_cnv_input)
    # -----
    mx_conv = read_partscsv(file_cnv_input)
    if i_cnv == 0:    
        tsr_bend1 = torch.tensor(mx_conv).float()
    elif i_cnv == 1:
        tsr_bend2 = torch.tensor(mx_conv).float()
    elif i_cnv == 2:
        tsr_bend3 = torch.tensor(mx_conv).float()
    elif i_cnv == 3:
        tsr_bend4 = torch.tensor(mx_conv).float()
    elif i_cnv == 4:
        tsr_line1 = torch.tensor(mx_conv).float()
    elif i_cnv == 5:
        tsr_line2 = torch.tensor(mx_conv).float()
    elif i_cnv == 6:
        tsr_datum = torch.tensor(mx_conv).float()

# -------------------------------
# 畳み込みカーネルを生成する
kernels = torch.stack([tsr_bend1, tsr_bend2, tsr_bend3, tsr_bend4, tsr_line1, tsr_line2, tsr_datum])
#print(kernels)

##########################
# 標準画像を読み込み表示する
##########################

# 標準画像を読み込み表示する
list_image = ["NA"]*10
list_image[0] = "image_circle"
list_image[1] = "image_cross"
list_image[2] = "image_missing_circle"
list_image[3] = "image_missing_circle_20_0_0"
list_image[4] = "image_missing_circle_20_10_-10"
list_image[5] = "image_rotated_rect"
list_image[6] = "image_rotated_rect_20_0_0"
list_image[7] = "image_rotated_triangle_20_0_-10"
list_image[8] = "image_rounded_rect"
list_image[9] = "image_standard_rect"
#print(list_image)

# ----
# 計測データの読み込みと畳み込みを行う
mx_conv = np.zeros((len(list_image), max_cnv_parts, max_rtm_idx, max_rtm_col))    # i_img,k,i,j

# 計測データを生成するための繰り返し計算
for i_img in range(len(list_image)):    # len(list_image)

    filename = nam_dir+nam_subdir2+list_image[i_img]+".csv"
    print(filename)
    temp_measure = read_imagecsv(filename)
    # ---
    # 正規化
    mx_measure = temp_measure/255
    #print("--------")
    #print(mx_measure.shape)
    # ---------------------------
    for k in range(max_cnv_parts):   # カーネルの種類
        for icnt,i in enumerate(arr_str_idx):
            for jcnt,j in enumerate(arr_str_col):
                mx_cut = cut_DataArea(i, j, max_cnv_idx, max_cnv_col, mx_measure)     # データを切り出す          
                # カット領域をテンソル化する
                mx_tsr = torch.tensor(mx_cut).float()     # テンソル化する
                #print("---- mx_tsr ----")
                #print(mx_tsr)
                # 畳み込みを行う
                val_conv = round(apply_kernel(kernels[k], mx_tsr).item(),3)
                #print("icnt:{},jcnt:{},val_conv:{}".format(icnt,jcnt,val_conv))
                # マトリックスを形成する
                mx_conv[i_img,k,icnt,jcnt] = val_conv

# ----
# 入力する類似度マトリックスの表示
#print(mx_conv)

#=================+================================
# MAIN PROGRAM : SOART3メトリックスを生成する
#=================================================
# ----
# 初期化
mx_soart = np.zeros((len(list_image), (max_cnv_parts-1)*3))
# ----
# 繰り返し
for i_img in range(len(list_image)):

    # ----
    # 標準ベクトルの読み込み
    mx_standard = mx_conv[i_img,6,:,:]
    arr_standard = mx_standard.flatten()
    #print("--------")
    #print(arr_standard)
    # ----
    # 初期化
    sub_soart = np.zeros((max_cnv_parts-1, 3))
    # 計測データの読み込みとSOART3メトリックスの生成
    for k in range(6):

        # ---------------------------
        # 計測ベクトルの読み込み
        mx_measure = mx_conv[i_img,k,:,:]
        arr_measure = mx_measure.flatten()
        print("--------")
        #print("k:{},arr_measure:{}".format(k,arr_measure))

        # ---------------------------
        # Primitive image(beta, yita, gamma)を計算する
        arr_soart = calc_PrimImage(arr_standard, arr_measure)
        print("i_img:{}, k:{}, arr_soart:{}".format(i_img,k,arr_soart))
        sub_soart[k, :] = arr_soart      
    # ----
    arr_soart = sub_soart.flatten()
    #print(arr_soart)
    mx_soart[i_img,:] = arr_soart
# ----
# 結果を表示する
#print(mx_soart)
# ------
# データフレームを形成する
arr_column = ["B1beta", "B1yita", "B1gamma", "B2beta", "B2yita", "B2gamma",
              "B3beta", "B3yita", "B3gamma", "B4beta", "B4yita", "B4gamma",
              "L1beta", "L1yita", "L1gamma", "L2beta", "L2yita", "L2gamma"]
df_out = pd.DataFrame(mx_soart, columns=arr_column)
# 出力ファイル名を追加する
df_out["filename"] = list_image
#print(df_out)
# ------
# CSVファイルへの出力
filename_csv = nam_dir+nam_subdir4+"soartc_part1_csvfiles.csv"
df_out.to_csv(filename_csv)

```

QEU:FOUNDER ： “これ（↓）が、SOARTCのメトリックス群の出力結果です。ちなみに、あとで小生が「type」欄で分類しています。”

![imageJRL9-5-6](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-6.jpg)

D先生 ： “メトリックスが(6x3=)18項目もあるんでしょう？この表のままでは、図形別に比較する気も起きません。”

![imageJRL9-5-7](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-7.jpg)

C部長： “あっ、そうだ！！**標準SN比の考え方**を参考にして、標準ベクトルの値を横軸にしてグラフにしてみましょう。”

QEU:FOUNDER ： “それはいい。つづいて、グラフ作画用のプログラムをドン！”

```python
# 与えられたCSVファイルをまとめて、グラフ作画を行う
# モジュールのインポート
from fastai.vision.all import *
import pandas as pd
import numpy as np

#=================================================
# READ CSV FILES
#=================================================
# 画像CSVファイルを読み込み(分類して出力)
def read_filecsv(file_readcsv): 
 
    # ---------------------------
    # 画像CSVファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ---------------------------
    # 全データのデータフレーム
    mx_all = df
    # ---------------------------
    # standardのデータフレーム
    df_standard = df[df['type'] == 'standard']
    #print(df_standard)
    # ---------------------------
    # shapesのデータフレーム
    df_shapes = df[df['type'] == 'shapes']
    #print(df_shapes)
    # ---------------------------
    # missing_cのデータフレーム
    df_missingc = df[df['type'] == 'missing_c']
    #print(df_missingc)
    # ---------------------------
    # rectangleのデータフレーム
    df_rectangle = df[df['type'] == 'rectangle']
    #print(df_rectangle)
  
    return df_standard, df_shapes, df_missingc, df_rectangle

# ----
# 画像CSVファイルを読み込み(分類して出力)
filename = "soartc_part1_csvfiles.csv"
print(filename)
df_standard, df_shapes, df_missingc, df_rectangle = read_filecsv(filename)
#print(df_missingc)

# ----
# ベクトル化
arr_standard = df_standard.loc[:,"B1beta":"L2gamma"].values
mx_shapes = df_shapes.loc[:,"B1beta":"L2gamma"].values
mx_missingc = df_missingc.loc[:,"B1beta":"L2gamma"].values
mx_rectangle = df_rectangle.loc[:,"B1beta":"L2gamma"].values
#print(mx_missingc)

# ----
# ベクトル化
fig, ax = plt.subplots(2, 2)
fig.tight_layout()
# -----
ax[0][0].scatter(arr_standard, mx_shapes[0], s=100, c="yellow", marker="*", alpha=0.5, lin-ewidths=2, edgecolors="orange")
ax[0][0].scatter(arr_standard, mx_shapes[1], s=100, c="blue", marker="o", alpha=0.5, linewidths=2, edgecolors="purple")
ax[0][0].scatter(arr_standard, mx_shapes[2], s=100, c="red", marker="+")
ax[0][0].set_title("mx_shapes")
ax[0][0].set_xlabel("standard")
ax[0][0].set_ylabel("measurement")
ax[0][0].grid(True)
# -----
ax[0][1].scatter(arr_standard, mx_missingc[0], s=100, c="yellow", marker="*", alpha=0.5, lin-ewidths=2, edgecolors="orange")
ax[0][1].scatter(arr_standard, mx_missingc[1], s=100, c="blue", marker="o", alpha=0.5, lin-ewidths=2, edgecolors="purple")
ax[0][1].scatter(arr_standard, mx_missingc[2], s=100, c="red", marker="+")
ax[0][1].set_title("mx_missingc")
ax[0][1].set_xlabel("standard")
ax[0][1].set_ylabel("measurement")
ax[0][1].grid(True)
# -----
ax[1][0].scatter(arr_standard, mx_rectangle[0], s=100, c="yellow", marker="*", alpha=0.5, lin-ewidths=2, edgecolors="orange")
ax[1][0].scatter(arr_standard, mx_rectangle[1], s=100, c="blue", marker="o", alpha=0.5, lin-ewidths=2, edgecolors="purple")
ax[1][0].set_title("mx_rectangle")
ax[1][0].set_xlabel("standard")
ax[1][0].set_ylabel("measurement")
ax[1][0].grid(True)
# -----
plt.show()

```

D先生 ： “そして、このプログラムを実行してグラフが出ました。ロジックから鑑みて当たり前だが、こんな風（↓）になるのか・・・。我々のSOART3ロジックは、メトリックスを対数変換して使っていますが、その判断は良かったですね。”

![imageJRL9-5-8](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-8.jpg)

QEU:FOUNDER ： “これから、SOARTCの「下：PART2」の段階に行きましょう。”


## ～ まとめ ～

QEU:FOUNDER ： “ワロタ・・・。”

[![MOVIE1](http://img.youtube.com/vi/TqhESn8ZWYo/0.jpg)](http://www.youtube.com/watch?v=TqhESn8ZWYo "栗原康氏出演！『ナイチンゲールから“近代的個人を超える人”を考える！？』")

C部長 : “あの有名なナイチンゲールって、そうだったんですね。ホント、知らなかった・・・。FOUNDERは「神の声を聴いた」ことはありますか？”

![imageJRL9-5-9](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-9.jpg)

QEU:FOUNDER ： “あるわけないだろ・・・。でもね、「とてつもなく明確なコンセプトを思いついた」っていうのはありますよ。QEUプロジェクトのコンセプトって、基本的に十数年変わっていないし・・・。”

![imageJRL9-5-10](/2024-03-01-QEUR23_VTFDEV4/imageJRL9-5-10.jpg)

QEU:FOUNDER ： “ちなみに、現在はコンセプトは社会の変化と新技術の導入と共に発展されています。現在は、コンセプトの基本である外観検査自動機の開発をやっているわけです。”

C部長 : “コンセプトって大事ですね。”

QEU:FOUNDER ： “良いコンセプトが基本にあれば、あとは好きなことをやっていればいいんですよ（笑）。”

