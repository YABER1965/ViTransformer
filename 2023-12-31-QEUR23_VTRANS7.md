---
title: QEUR23_VTRANS7: [PyTorch]アテンション・マップを作ってみる
date: 2023-12-31
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VTRANS7: [PyTorch]アテンション・マップを作ってみる

## ～ より分かりやすくなった ～

D先生 ： “いままでのところ、Kerasでアテンション・マップを作れるところまできました。次は、何します？”

![imageJRL8-8-1](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-1.jpg)

QEU:FOUNDER ： “PyTorchで、アテンション・マップをつくりましょう。例えば、以下のクルマの写真を**アテンション・マップを使って「分解」**してみましょう。”

![imageJRL8-8-2](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-2.jpg)

C部長 : “おっ！「分解」ってすごそう！！それにしても、PyTorchでアテンションマップを作るために、ずいぶんサーチしましたよね。Kerasが簡単だったので、意外でした・・・。”

QEU:FOUNDER ： “いまから考えると、**「当たり前すぎて誰も紹介しなかった」**かもしれない・・・（笑）。それでも、現在は「志半ば」という感じかな・・・。・・・まあいいや、プログラムをドン・・・。”

```python
! pip install transformers torchvision torch

# -----
# https://huggingface.co/google/vit-base-patch16-224
# Vision Transformer (base-sized model)

from transformers import ViTFeatureExtractor, ViTForImageClassification
from PIL import Image

image = Image.open("./automotive_002.jpg")
display(image)

# ------
processor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
print(model)

# ------
inputs = processor(images=image, return_tensors="pt")
outputs = model(**inputs)
logits = outputs.logits
# model predicts one of the 1000 ImageNet classes
predicted_class_idx = logits.argmax(-1).item()
print("Predicted class:", model.config.id2label[predicted_class_idx])

```

**（推論の結果）**

![imageJRL8-8-3](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-3.jpg)

D先生 ： “さすが、天下のG社のモデルです。とてもうまく推論しているようですね。これは、ベースモデルですよね。”

QEU:FOUNDER  ： “車を検出したいのだったら、本来はファインチューンされている方がよいかな。でも、アテンション・マップを出すだけだから、どちらでもいいでしょう。”

```python
# -----
from transformers import ViTFeatureExtractor

feature_extractor = ViTFeatureExtractor.from_pretrained("facebook/dino-vits8", size=480)
# ---
pixel_values = feature_extractor(images=image, return_tensors="pt").pixel_values 
print(pixel_values.shape)

# -----
from transformers import ViTModel

model = ViTModel.from_pretrained("facebook/dino-vits8", add_pooling_layer=False)
# ---
# forward pass
outputs = model(pixel_values, output_attentions=True, interpolate_pos_encoding=True)
#print(outputs)

# -----
attentions = outputs.attentions[-1] # we are only interested in the attention maps of the last layer
nh = attentions.shape[1] # number of head
print("number of head:", nh)

# -----
# we keep only the output patch attention
attentions = attentions[0, :, 0, 1:].reshape(nh, -1)
print(attentions.shape)

# -----
import os
import torch
import torch.nn as nn
import torchvision
import matplotlib as plt

# ---
threshold = 0.6
w_featmap = pixel_values.shape[-2] // model.config.patch_size
h_featmap = pixel_values.shape[-1] // model.config.patch_size

# we keep only a certain percentage of the mass
val, idx = torch.sort(attentions)
val /= torch.sum(val, dim=1, keepdim=True)
cumval = torch.cumsum(val, dim=1)
th_attn = cumval > (1 - threshold)
idx2 = torch.argsort(idx)
for head in range(nh):
    th_attn[head] = th_attn[head][idx2[head]]
th_attn = th_attn.reshape(nh, w_featmap, h_featmap).float()
# interpolate
th_attn = nn.functional.interpolate(th_attn.unsqueeze(0), scale_factor=model.config.patch_size, mode="nearest")[0].cpu().numpy()

attentions = attentions.reshape(nh, w_featmap, h_featmap)
attentions = nn.functional.interpolate(attentions.unsqueeze(0), scale_factor=model.config.patch_size, mode="nearest")[0].cpu()
attentions = attentions.detach().numpy()

# show and save attentions heatmaps
output_dir = '.'
os.makedirs(output_dir, exist_ok=True)
torchvision.utils.save_image(torchvision.utils.make_grid(pixel_values, normalize=True, scale_each=True), os.path.join(output_dir, "img.png"))
for j in range(nh):
    fname = os.path.join(output_dir, "attn-head" + str(j) + ".png")
    plt.figure()
    plt.imshow(attentions[j])
    plt.imsave(fname=fname, arr=attentions[j], format='png')
    #print(f"{fname} saved.")

```

QEU:FOUNDER  ： “まずは、アテンション・マップの1レイヤー目の結果を見てみましょう。”

**(その１:車)**

![imageJRL8-8-4](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-4.jpg)

C部長 : “おお・・・。うっすらと、「クルマ」の様子が見える・・・。”

QEU:FOUNDER ： “ついでに、同じプログラムで**「猫様」を処理してみた**ので、その比較もして見ましょう。”

**（猫の元画像）**

![imageJRL8-8-5](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-5.jpg)

**(その１:猫)**

![imageJRL8-8-6](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-6.jpg)

C部長 : “クルマとネコの比較って・・・。”

D先生 ： “次のレイヤーに進めましょう。”

**（その３:車）**

![imageJRL8-8-7](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-7.jpg)

**(その３:猫)**

![imageJRL8-8-8](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-8.jpg)

C部長 : “おお・・・。タイヤが検出されとる・・・。でも、猫様の場合はコレ（↑）なのか？”

QEU:FOUNDER ： “次にいってみましょう。”


**（その５:車）**

![imageJRL8-8-9](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-9.jpg)

**(その５:猫)**

![imageJRL8-8-10](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-10.jpg)

C部長 : “ここは、フロントガラスなのか・・・。でも、猫様との整合性がつかん・・・（笑）。”

QEU:FOUNDER  ： “小生もよくわからんが、おもしろいと思わん？ちなみに、ViTの学習方法は、CNNと全く違うようです。”

**（レイヤー１：CNNの場合）**

![imageJRL8-8-11](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-11.jpg)

**（レイヤー２：CNNの場合）**

![imageJRL8-8-12](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-12.jpg)

D先生 ： “CNN（畳み込みニューラルネット）の場合には、**画像の認識の方法が「パーツ単位」である**のに対し、ViT(Vision Transformer)は**全体的**ですね。結果として、**不良画像を作りたいというニーズにViTがより合っている**という・・・。そういえば、私には質問があります。推論時とアテンション・マップの生成時に使っているモデルは違いますね。これはわざとですか？”

**（ViTModel）**

![imageJRL8-8-13](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-13.jpg)

The bare ViT Model transformer outputting raw hidden-states without any specific head on top. This model is a PyTorch torch.nn.Module subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage and behavior.
特別なヘッドオントップなしで生の隠れ状態を出力するベア ViT モデル トランスフォーマー。 このモデルは、PyTorch torch.nn.Module サブクラスです。 これを通常の PyTorch モジュールとして使用し、一般的な使用法と動作に関するすべての事項については PyTorch ドキュメントを参照してください。

QEU:FOUNDER  ： “このメソッドの出力の中にアテンション・マップ（多レイヤーのマトリックス）を出力するための機能があります。・・・つまり、HuggingFaceのtransformersにはアテンション・マップを出力する機能が「標準装備」されているんです。ただし、誰もそのことを言ってくれなかった。”

C部長 : “そういうわけで、FOUNDERはPyTorch版のアテンション・マップを生成させるのにKerasよりも苦労したわけですね。”

D先生 ： “我々は外観検査自動機として、当該不良の部分をマップ出力させたい。しかし、どのレイヤーから、それが出力されるのかがわからないんですよねえ・・・。”

QEU:FOUNDER ： “どのモデルを使うか、学習のさせ方、さらにはアテンション・マップを出力するためのレイヤーの選択によって変わります。ここらへんのトライ・エラーは普通にあるんじゃない？”

C部長 : “要するに**「場数」**ですね。場数をこなすための「寄付」をお願いします。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER  ： “C大先生がいいことを言った！！”


## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “検査とはISO9001の解釈では「リリース」です。リリースが変わると、システムの本質が変わる。ISO9001なんかもういらない。TQMなんか百害あって一利もない。TQMって、小生に言わせるとコレ（↓）と同じ・・・。”

[![MOVIE1](http://img.youtube.com/vi/otOwbofeenc/0.jpg)](http://www.youtube.com/watch?v=otOwbofeenc "【狂気】宝塚自●事件。史上最悪の宝塚記者会見から･･･更なる狂気の行動。宝塚の事件からわかる、あなたの人生を蝕むハラスメントの本質を解説する。安冨歩東大教授")

D先生 ： “ISO9001とか、TQMって**古い技術**なんです。最新の産業のフェイズがインダストリー5.0として、ISO-TQMあたりは**インダストリー3.5**と言われています。J国は、ちょっと**古い技術を「引っ張りすぎた」**のだよね・・・。”

![imageJRL8-8-14](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-14.jpg)

C部長 : “あれ？2013年の年頭あたりに、ドイツからインダストリー4.0の概念が紹介され、J国の産業界に衝撃を与えました。そのとき、ボクは興味があって年頭の新聞記事を読んでいたら、すべての経営者が**「このレベルはもうやっている」**って、軽く見ていていましたよね。”


**[検査の目的は不良発見のときの利益である]**

検査方法が決まっているとき、検査するかしないかは工程から出てくる製品の品質水準のいかんによる。品質水準が悪ければ検査をしたほうが良いし、品質水準がわるくなければ無検査が望ましい。
検査の目的はどこにあるのだろうか。それは不良品を発見したときに、利益が生まれるのである。（中略）したがって、検査の研究とは、安くて確実な検査方法を開発すること。開発した検査方法の経済的価値を計算し、検査工程を設置すべきかどうかを決めること。
（出典は敢えて言いません）

QEU:FOUNDER ： “そういうのをなんというか知ってる？「愚か者」・・・（笑）。会社単位でみると、アウトプットが同じなので経営者からみると同じに見えます。ただし、社内における「負荷のバランス」が全然かわります。インダストリー3.5レベルの技術では、**所定のアウトプットを出すのに従業員にどれだけの負荷をかける**を知っている？知らんでしょ？”

![imageJRL8-8-15](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-15.jpg)

QEU:FOUNDER ： “そんなにスゴイのであれば、どうして追い越されるの？**消費者はモノの本質を見ているんです。**”

![imageJRL8-8-16](/2023-12-31-QEUR23_VTRANS7/imageJRL8-8-16.jpg)

QEU:FOUNDER  ： “そもそも、従業員は**自社の製品の最大の消費者であり、ファンだから**ね。理想をいえば・・・（笑）。働きやすい職場の製品が売れるようになるのは当たり前です。経営者の上から目線は無意味なんですよ。それでは、**デミングのマネジメントの14か条**をみてみましょう。”

- 競争力を保つため、製品やサービスの向上を常に心がける環境を作る。
- 最高経営者がその責任者を決める。
- 新しい哲学を採用する。我々は新たな経済時代にいる。遅延、間違い、材料の欠陥、作業の欠陥などの一般常識となっている水準には満足できない。
- 全品検査への依存を止める。品質は統計的手法で向上させる（完成後に欠陥を見つけるのではなく、欠陥を防止せよ）。
- 価格だけに基づいて業者を選定することを止める。価格と品質によって選定する。統計的手法に基づく品質保証のできない業者は排除していく。
- 問題を見逃さない。
- 全体（設計、受け入れ材料、製造、保守、改良、トレーニング、監視、再教育）を継続的に向上させるのがマネジメントの役割である。
- 職場教育（OJTなど）の手法を導入し、義務付ける。
- 職場のリーダーは単に数値ではなく品質で評価せよ。それによって自動的に生産性も向上する。
- マネジメントは、職場のリーダーから様々な障害（固有の欠陥、保守不足の機械、貧弱なツール、あいまいな作業定義など）について報告を受けたら、迅速に対応できるよう準備しておかなければならない。
- 社員全員が会社のために効果的に作業できるよう、不安を取り除く。
- 部門間の障壁を取り除く。研究、設計、販売、製造の各部門の人々は様々な問題に一丸となって対応しなければならない。
- 数値目標を排除する。新たな手法も提供せずに生産性の向上だけをノルマとしない。数値割り当てを規定する作業標準を作業者やマネジメントから排除する。時間給作業員から技量のプライドを奪わない。とりわけ年次・長所によって評価することや目標による管理は廃止する。
- 強健な教育プログラムを実施する。全員で変革に取り組む。最高経営陣の中で、上記13ポイントを徹底させる構造を構築する。

D先生 ： “うわあ・・・、なつかしい・・・。**デミングがモデルにしたのは、彼が見た「J国企業の姿」だった**んですよね！”

### オッサン： 従業員の皆さんにはテレビを見てください。皆が同じように考えてください。
### オッサン：“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ。
### オッサン：私の使命はこの会社で終身雇用制を実現することにある。(わざわざ海外の会社でこれを言うバカ)

QEU:FOUNDER ： “J国も劣化したもんだ・・・（笑）。ただし、検査に対する見方、PPM品質時代における統計的手法の有用性など、修正が必要となる部分はたくさんある。”

C部長 : “今、本当に再評価が必要なのは、彼の言葉なのでしょう。”

QEU:FOUNDER ： “**もっとサプライヤを大切にしなきゃ・・・。**インダストリー5.0の時代において、品質保証に責任があるのは顧客です。サプライアの責任はコストだけですよ。”

