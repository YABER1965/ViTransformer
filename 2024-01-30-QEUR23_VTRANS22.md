---
title: QEUR23_VTRANS22:  ViTモデルをハウジング形状を変えて学習する（前回からつづく）
date: 2024-01-30
tags: ["QEUシステム", "メトリックス", "Python言語", "Vision Transformer", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: Vision Transformer(ViT)をやってみる
---

## QEUR23_VTRANS22:  ViTモデルをハウジング形状を変えて学習する（前回からつづく）

## ～ このように、（暫定）PRE-TRAINのモデルが出来上がり ～

### ・・・ 前回のつづきです ・・・

B係長 ： “300回の学習では、画像上のアテンションが強い位置は画面上に多数ばらついていますね。これが学習の進展とともに、どうなるのか・・・？ちなみに、これは「ミックス端子」の学習の場合です。”

![imageJRL8-23-1](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-1.jpg)

A係長 ： “（学習の進展とともに）アテンションが強いポイントの数が少なく、しかも徐々に正確な位置にシフトしてきています。もちろん、いまだにハウジングにアテンションが強くなるケースが多々ありますが・・・。”

**（ミックス端子、学習エポック数：500）**

![imageJRL8-23-2](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-2.jpg)

B係長 ： “意外と学習とともに、アテンションの位置は動くんですね。これは、ちょっとした発見でした・・・。逆に言うと、アテンション・マップを見ることによって、どのような学習データを追加すべきかのヒントが得られますね。さて、ここからがAさんの提案で、**「（コネクタ）ハウジング」を変更したデータ**を追加しましょう。”

![imageJRL8-23-3](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-3.jpg)

A係長 ： “たしかに、新たにコネクタの一部に凸凹がついていますね。これは、むりやり手動で付けたのですか？Pythonなしに・・・。”

B係長 ： “もちろん・・・。Blender-Pythonのプログラムは端子専用ですから・・・。Aさん、この学習データを追加して、学習してくれない？”

**（ViT学習過程）**

![imageJRL8-23-4](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-4.jpg)

**（アテンション・マップ）**

![imageJRL8-23-5](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-5.jpg)

A係長 : “学習パフォーマンスからみると、前回のものと差はありません。アテンション・マップは例によって、学習の初期は分布がばらついています。アテンション・マップの変化を時系列でみてみましょう。”

**（学習300回目）**

![imageJRL8-23-6](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-6.jpg)

**（学習400回目）**

![imageJRL8-23-7](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-7.jpg)

B係長 ： “う～ん・・・。コネクタ上のアテンションは、なかなか減らないねえ・・・。今回のトライアル（異種コネクタの追加）は効果がなかったんだろうか・・・。”

A係長 : “これについては、何とも言えんね。ともあれ、（我々は）少なくとも「正しい方向」のことをやってきたんだし・・・。もう少し、（学習を）つづけてみましょう。”

**（学習500回目）**

![imageJRL8-23-8](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-8.jpg)

A係長 : “・・・あれ？判断、または予測が「OK」の画像が特徴的になってきました。”

B係長 ： “OKの画像のアテンション・マップでは、アテンションの分布がより散らばるんです。一方、異常検出した画像は、アテンションの位置がきまるんです。”

A係長 : “ほう・・・。もうちょっとだけ学習をつづける気合がでてきました・・・（笑）。最後の600回目の学習結果をドン！！”

**（ViT学習過程）**

![imageJRL8-23-9](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-9.jpg)

**（アテンション・マップ）**

![imageJRL8-23-10](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-10.jpg)

A係長 ： “・・・いやあ、このアテンション・マップの出来はいいわぁ・・・。”

B係長 : “コネクタ上にアテンションがつくのに目をつぶるとね・・・。さらに、**ViTモデルの判別精度がとうとう90％に近づいてきました**。このレベルの精度では、このようなマップになるんですね。”

![imageJRL8-23-11](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-11.jpg)

B係長 : “ひょっとして、これがVisual Transformerの真の実力なのかもしれないですね。・・・まあ、これでモデルの学習はOKかな？”

A係長 ： “今回はあくまでテストですからね・・・。ただし、本当に「モノにする（現場で使う）」には、コネクタ破損や異品、異物などのいろいろな不良モードを加える必要があります。”

![imageJRL8-23-12](/2024-01-30-QEUR23_VTRANS22/imageJRL8-23-12.jpg)

A係長 ： “そうすると、とんでもなくデータ数が増えるし、計算時間もかかる。当然ながら、**将来的にはファイン・チューニングの導入は不可避**ですね。”

B係長 ： “ここまで来て、**本プロジェクト（SOART3+ViTによる外観検査の自動化）は成功したといえますね**。ご褒美として、カンパをいただけませんか？”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

A係長  ： “次は、「ウイニング・ラン」です。”


## ～ まとめ ～

QEU:FOUNDER ： “今回のプロジェクトについて、一応、課題の整理をしておきたい。”

C部長 : “おや？ずいぶん気が早いですね。”

QEU:FOUNDER ： “もう、完全に**「我々の考える成功のレベルに達した」**からね。ただし、これから先は自分らではなんともならない。そこらへんの課題を披露しておきたい。”

[![MOVIE1](http://img.youtube.com/vi/awyWND506NY/0.jpg)](http://www.youtube.com/watch?v=awyWND506NY "Image Classification Using Vision Transformer | ViTs")

QEU:FOUNDER ： “ちなみに、このYoutuber（↑）がやっていることを少しだけ拡張すればいいんだけどね。 “

D先生 ： “それって、要するに「ViTモデルのファイン・チュ―ニング」のことでしょ？ “

QEU:FOUNDER ： “この事例(↑)では、第3者がつくったPre-train(PT)モデルをつかってファイン・チューニングをしています。しかし、今の段階で**世の中で手に入るPTモデルは物体の判別用であって、異常検出用のモノではない**です。さらに、SOART3合成画像なんかは使っていないでしょ？ “

C部長 : “自分でPTモデルを学習し、それを使ってファインチューニングするんだ。これは、たいへんだなぁ・・・。”

QEU:FOUNDER ： “今後、このテクノロジを皆が使うようになれば、どんどん楽になっていくと思うよ。あと、より数多くの事例で使えば使うほど、このシステムのありがたみがわかってきます。我々は、ViTモデルのカスタム構築についての資料が手に入らないので、あとの課題は各自でやってみてください。PythonプログラミングとPytorchを知っている人が、ある程度の時間とお金（コースの受験、本、記事の購入など）を投入すれば、実現はそんなに難しくはないとおもいます。”
